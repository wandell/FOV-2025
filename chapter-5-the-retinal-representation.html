<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>5&nbsp; Retina – Foundations of Vision (2nd Edition)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter-6-the-cortical-representation.html" rel="next">
<link href="./part-2-image-representation.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part-2-image-representation.html">Image Representation</a></li><li class="breadcrumb-item"><a href="./chapter-5-the-retinal-representation.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Retina</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Foundations of Vision (2nd Edition)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">How to study vision</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Image Encoding</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part-1-image-encoding-v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Image Encoding</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-2-image-formation-v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Image Formation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-3-the-photoreceptor-mosaic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Photoreceptor Mosaic</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-4-wavelength-encoding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Wavelength Encoding</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Image Representation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part-2-image-representation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Image Representation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-5-the-retinal-representation.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Retina</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-6-the-cortical-representation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Cortical Representation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-7-pattern-sensitivity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pattern Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-8-multiresolution-image-representations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Multiresolution Representations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Image Interpretation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part-3-image-interpretation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Image Interepretation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-9-color.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Color</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-10-motion-and-depth.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Motion and Depth</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-11-seeing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Seeing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Appendix</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./computational-examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Computational examples</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./online-teaching-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Online Teaching Resources</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#retinal-overview" id="toc-retinal-overview" class="nav-link active" data-scroll-target="#retinal-overview"><span class="header-section-number">5.1</span> Retinal overview</a>
  <ul class="collapse">
  <li><a href="#retinal-structure" id="toc-retinal-structure" class="nav-link" data-scroll-target="#retinal-structure"><span class="header-section-number">5.1.1</span> Retinal structure</a></li>
  <li><a href="#retinal-function-specialization" id="toc-retinal-function-specialization" class="nav-link" data-scroll-target="#retinal-function-specialization"><span class="header-section-number">5.1.2</span> Retinal function: specialization</a></li>
  <li><a href="#retinal-function-image-contrast-and-adaptation" id="toc-retinal-function-image-contrast-and-adaptation" class="nav-link" data-scroll-target="#retinal-function-image-contrast-and-adaptation"><span class="header-section-number">5.1.3</span> Retinal function: image contrast and adaptation</a></li>
  </ul></li>
  <li><a href="#visual-streams" id="toc-visual-streams" class="nav-link" data-scroll-target="#visual-streams"><span class="header-section-number">5.2</span> Visual Streams</a>
  <ul class="collapse">
  <li><a href="#methods-of-classifying-neurons" id="toc-methods-of-classifying-neurons" class="nav-link" data-scroll-target="#methods-of-classifying-neurons"><span class="header-section-number">5.2.1</span> Methods of classifying neurons</a></li>
  <li><a href="#morphology-of-parasol-and-midget-ganglion-cells" id="toc-morphology-of-parasol-and-midget-ganglion-cells" class="nav-link" data-scroll-target="#morphology-of-parasol-and-midget-ganglion-cells"><span class="header-section-number">5.2.2</span> Morphology of Parasol and Midget Ganglion Cells</a></li>
  <li><a href="#variation-with-retinal-eccentricity" id="toc-variation-with-retinal-eccentricity" class="nav-link" data-scroll-target="#variation-with-retinal-eccentricity"><span class="header-section-number">5.2.3</span> Variation with retinal eccentricity</a></li>
  <li><a href="#central-projections" id="toc-central-projections" class="nav-link" data-scroll-target="#central-projections"><span class="header-section-number">5.2.4</span> Central Projections</a></li>
  <li><a href="#conduction-time-and-contrast-gain" id="toc-conduction-time-and-contrast-gain" class="nav-link" data-scroll-target="#conduction-time-and-contrast-gain"><span class="header-section-number">5.2.5</span> Conduction Time and Contrast Gain</a></li>
  <li><a href="#visual-information-encoded-by-the-parvocellular-and-magnocellular-pathways" id="toc-visual-information-encoded-by-the-parvocellular-and-magnocellular-pathways" class="nav-link" data-scroll-target="#visual-information-encoded-by-the-parvocellular-and-magnocellular-pathways"><span class="header-section-number">5.2.6</span> Visual Information Encoded by the Parvocellular and Magnocellular Pathways</a></li>
  </ul></li>
  <li><a href="#retinal-ganglion-cell-response-to-light" id="toc-retinal-ganglion-cell-response-to-light" class="nav-link" data-scroll-target="#retinal-ganglion-cell-response-to-light"><span class="header-section-number">5.3</span> Retinal Ganglion Cell Response To Light</a>
  <ul class="collapse">
  <li><a href="#center-surround-organization" id="toc-center-surround-organization" class="nav-link" data-scroll-target="#center-surround-organization"><span class="header-section-number">5.3.1</span> Center-Surround Organization</a></li>
  <li><a href="#measurements-of-receptive-fields" id="toc-measurements-of-receptive-fields" class="nav-link" data-scroll-target="#measurements-of-receptive-fields"><span class="header-section-number">5.3.2</span> Measurements of Receptive Fields</a></li>
  <li><a href="#steady-state-measurements" id="toc-steady-state-measurements" class="nav-link" data-scroll-target="#steady-state-measurements"><span class="header-section-number">5.3.3</span> Steady-state Measurements</a></li>
  <li><a href="#the-stimulus." id="toc-the-stimulus." class="nav-link" data-scroll-target="#the-stimulus."><span class="header-section-number">5.3.4</span> The stimulus.</a></li>
  <li><a href="#the-response." id="toc-the-response." class="nav-link" data-scroll-target="#the-response."><span class="header-section-number">5.3.5</span> The response.</a></li>
  </ul></li>
  <li><a href="#testing-contrast-linearity." id="toc-testing-contrast-linearity." class="nav-link" data-scroll-target="#testing-contrast-linearity."><span class="header-section-number">5.4</span> Testing contrast linearity.</a>
  <ul class="collapse">
  <li><a href="#the-two-dimensional-receptive-field" id="toc-the-two-dimensional-receptive-field" class="nav-link" data-scroll-target="#the-two-dimensional-receptive-field"><span class="header-section-number">5.4.1</span> The Two-Dimensional Receptive Field</a></li>
  <li><a href="#contrast-sensitivity-functions" id="toc-contrast-sensitivity-functions" class="nav-link" data-scroll-target="#contrast-sensitivity-functions"><span class="header-section-number">5.4.2</span> Contrast Sensitivity Functions</a></li>
  <li><a href="#why-contrast-patterns-are-important" id="toc-why-contrast-patterns-are-important" class="nav-link" data-scroll-target="#why-contrast-patterns-are-important"><span class="header-section-number">5.4.3</span> Why contrast patterns are important</a></li>
  <li><a href="#connections-to-different-cone-types" id="toc-connections-to-different-cone-types" class="nav-link" data-scroll-target="#connections-to-different-cone-types"><span class="header-section-number">5.4.4</span> Connections to Different Cone Types</a></li>
  <li><a href="#spatio-temporal-analysis-lines-and-spots" id="toc-spatio-temporal-analysis-lines-and-spots" class="nav-link" data-scroll-target="#spatio-temporal-analysis-lines-and-spots"><span class="header-section-number">5.4.5</span> Spatio-Temporal Analysis: Lines and Spots</a></li>
  <li><a href="#spatio-temporal-measurements-harmonic-functions" id="toc-spatio-temporal-measurements-harmonic-functions" class="nav-link" data-scroll-target="#spatio-temporal-measurements-harmonic-functions"><span class="header-section-number">5.4.6</span> Spatio-Temporal Measurements: Harmonic Functions</a></li>
  <li><a href="#sec-retina-separability" id="toc-sec-retina-separability" class="nav-link" data-scroll-target="#sec-retina-separability"><span class="header-section-number">5.4.7</span> Space-time separability</a></li>
  <li><a href="#the-difference-of-gaussian-model" id="toc-the-difference-of-gaussian-model" class="nav-link" data-scroll-target="#the-difference-of-gaussian-model"><span class="header-section-number">5.4.8</span> The Difference of Gaussian Model</a></li>
  </ul></li>
  <li><a href="#retinal-light-adaptation" id="toc-retinal-light-adaptation" class="nav-link" data-scroll-target="#retinal-light-adaptation"><span class="header-section-number">5.5</span> Retinal Light Adaptation</a>
  <ul class="collapse">
  <li><a href="#contrast-sensitivity-dependence-on-mean-intensity" id="toc-contrast-sensitivity-dependence-on-mean-intensity" class="nav-link" data-scroll-target="#contrast-sensitivity-dependence-on-mean-intensity"><span class="header-section-number">5.5.1</span> Contrast Sensitivity: Dependence on Mean Intensity</a></li>
  <li><a href="#comparison-with-behavioral-contrast-sensitivity" id="toc-comparison-with-behavioral-contrast-sensitivity" class="nav-link" data-scroll-target="#comparison-with-behavioral-contrast-sensitivity"><span class="header-section-number">5.5.2</span> Comparison with Behavioral Contrast Sensitivity</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part-2-image-representation.html">Image Representation</a></li><li class="breadcrumb-item"><a href="./chapter-5-the-retinal-representation.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Retina</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-retinal-representation" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Retina</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="retinal-overview" class="level2 page-columns page-full" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="retinal-overview"><span class="header-section-number">5.1</span> Retinal overview</h2>
<p>In this chapter we will review the structure of the retina and its role in organizing visual information. The retina is a thin layer of neural tissue that lines the eye. After the retinal image is encoded by the photoreceptors, neurons within the retina transform the photoreceptor signals into a new representation that is carried by the optic nerve to a variety of locations in the brain. The retina is important for several reasons. First, the retina is important to neuroscientists because it is a very accessible part of the central nervous system making it an important site for scientific study Second, the retina is important to clinicians since it is the only part of the central nervous system that can be examined directly, by using an opthalmoscope. Third, the retina is important to vision scientists because it has several important visual functions, including encoding the image and transforming it into a collection of separate pathways that send information about the entire retinal image to the brain. Since retinal neurons develop from the same progenitor cells that give rise to the brain, the organization of information within these retinal pathways is also an important clue about the organization within the brain as well.</p>
<section id="retinal-structure" class="level3 page-columns page-full" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="retinal-structure"><span class="header-section-number">5.1.1</span> Retinal structure</h3>
<p>Over most of its extent, the primate retina is approximately 0.5 mm thick and consists of three layers of cell bodies and two layers containing the synaptic interconnections between the neurons. Near the optical axis of the eye, however, the primate retina contains a specialized region, the fovea, consisting of only a single layer of neurons, the cone photoreceptors. Both of these structural properties of the retina can be seen in the anatomical cross-section section of a human retina shown in <a href="#fig-human-retina" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-human-retina</span></a>.</p>
<div id="fig-human-retina" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-human-retina-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/retina-fovea-labelled.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-human-retina-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.1: The human retina is a thin layer of neural tissue that lines the back of the eye. In the near periphery and periphery the retina is a layered structure. The cornea and lens would be at the top of this picture, so that in the periphery light must pass through the retinal layers before being absorbed by the photoreceptors. In the fovea the retina consists of only a single layer of photoreceptors as the neurons responsible for carrying the responses of the foveal cones are displaced to the side, out of the light path. (Source: A. Hendrickson, personal communication).
</figcaption>
</figure>
</div>
<p><a href="#fig-retinal-neurons" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-retinal-neurons</span></a> shows two types of retinal neurons and identifies some of their parts, including the dendritic fields, cell bodies, and axon. The dendritic fields receive input from other neurons; the axon, which may branch, carries the neuron’s output to its destination<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<div id="fig-retinal-neurons" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-retinal-neurons-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/neuron-updated.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-retinal-neurons-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.2: Retinal neurons have many different shapes and sizes. A midget bipolar and a parasol-type ganglion cell are shown. (a) The cell body of a bipolar cell resides in the inner nuclear layer. Its dendrites make contact with the photoreceptors and horizontal cells and its axon carries the output of the bipolar cell to the inner plexiform layer where it contacts the dendritic field of a ganglion cell. There are several different types of bipolar cells; the cell shown is a midget bipolar whose dendritic tree makes contact with a single photoreceptor and whose axon makes contact with a single ganglion cell. (Source: <span class="citation" data-cites="yamashita1991-rodbipolar">Yamashita and Wässle (<a href="#ref-yamashita1991-rodbipolar" role="doc-biblioref">1991</a>)</span>). (b) The retinal ganglion cell bodies reside in the ganglion cell layer of the retina. The axons of the retinal ganglion cells comprise the optic nerve. Several types of retinal ganglion cells can be distinguished based on the properties of their dendritic fields, their interconnections, and their cell bodies. The cells drawn here are midget and parasol cell (Source: <span class="citation" data-cites="dacey1992-mpganglion">D. M. Dacey and Petersen (<a href="#ref-dacey1992-mpganglion" role="doc-biblioref">1992</a>)</span>).
</figcaption>
</figure>
</div>
<p>There are five basic categories of retinal neurons, although each category has several subclassifications. The major categories of retinal neurons are distinguished by the location of their cell bodies, dendritic fields, and axon terminals. The photoreceptors’ cell bodies are located in the <em>outer nuclear layer</em> of the retina. The synaptic terminals of the photoreceptors make contact with the dendritic fields of the <em>bipolar</em> and <em>horizontal</em> cells in the <em>outer plexiform layer</em>. The cell bodies of the bipolar and horizontal cells are located in the <em>inner nuclear layer</em>. Both the dendrites and the branching axon terminals of the horizontal cells make connections with cells in the outer nuclear layer. The bipolar cells, however, make connections onto the the dendrites of the <em>ganglion cells</em> within the <em>inner plexiform layer</em>. Since only the bipolar cells link the signals in the outer and inner plexiform layers, all visual signals must pass through the bipolar cells.</p>
<p>The <em>amacrine</em> cell bodies are also located in the inner nuclear layer. Santiago Ramon y Cajal gave these cells their name to indicate that they have no identifiable axons, but only dendrites. The dendritic fields of the amacrine cells make connections with the dendritic fields of the ganglion cells in the inner plexiform layer. The retinal <em>ganglion</em> cell bodies are located in the <em>ganglion cell layer</em>, and their dendritic fields connect with the axon terminals of the bipolars and the dendritic fields of the amacrine cells.</p>
<p>The axons of the retinal ganglion cells provide the only retinal output signal. The ganglion cell axons comprise the <em>optic nerve</em> and they exit from the retina at a single location in the retina called the <em>optic disk</em>. There are no photoreceptors at the optic disk, so we do not encode or perceive the light that falls there. Consequently, the optic disk is also called the <em>blindspot</em>. We are not aware of the blindspot in our eyes ordinarily since the portion of the visual field falling in the blindspot of one eye falls on functional a retina in the other eye. You can perceive your blindspot by closing one eye and then carefully fixating with the other eye on the “x” in <a href="#fig-blindspot" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-blindspot</span></a>. Move the screen to a viewing distance where the white square disappears, roughly 25 cm from your nose. Notice that the white square and dot within the texture pattern fill in, while the dots at a comparable visual eccentricity are still visible. Thus, the dot disappears because of the blindspot and not because of a loss of visual acuity in the periphery.</p>
<div id="fig-blindspot" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-blindspot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/blindspot.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-blindspot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.3: A demonstration of the blindspot. Place the page about 25 cm from your eye. Then close your left eye and fixate the X: the white spot in the texture will disappear. If it does not, then slowly move the book back and forth, carefully maintaining fixation, until the spot does disappear. The two squares above and below become hard to see in the periphery, but they do not disappear. This demonstrates that the disappearance of the central square is not merely due to a general loss of visibility at this eccentricity.
</figcaption>
</figure>
</div>
</section>
<section id="retinal-function-specialization" class="level3 page-columns page-full" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="retinal-function-specialization"><span class="header-section-number">5.1.2</span> Retinal function: specialization</h3>
<p>The retina segregates visual information into parallel neural pathways specialized for different visual tasks. In earlier chapters, we reviewed one example of neural specialization in the retina: there are two different types of photoreceptors, the rods and the cones, that both sample the image. These two photoreceptors types are responsible for encoding the visual image in different intensity ranges.</p>
<div id="fig-rod-pathway" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-rod-pathway-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/rodPathway.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-rod-pathway-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.4: A rod-initiated pathway in the vertebrate retina. Axons from more than 1000 rods converge upon a single rod bipolar cell. The rod bipolar send their outputs to a specialized amacrine cell, the AII, located in the inner plexiform layer. The AII amacrine cell communicates the rod-initiated signal to two types of ganglion cells, one whose dendritic field is in the upper layers of the inner plexiform layer and another whose dendritic field is in the lower layers. The responses of ganglion cells whose dendritic fields are in the upper layer are decreased by light, while responses of ganglion cells whose dendritic fields are in the lower layer are increased by light (Source: <span class="citation" data-cites="boycott-wassle-1991">Wässle and Boycott (<a href="#ref-boycott-wassle-1991" role="doc-biblioref">1991</a>)</span>).
</figcaption>
</figure>
</div>
<p>The segregation of rod and cone signals continues through several synaptic connections within the retina. Kolb and her collaborators have shown that the signals initiated within the rods follow a separate rod pathway within the retina until the signals arrive at the retinal ganglion cells (see <a href="#fig-rod-pathway" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-rod-pathway</span></a>). The rods make connections with a class of bipolars, the rod bipolars, that integrate the responses of many different rod photoreceptors. Presumably, pooling the signals from many rods enhances the sensitivity of this rod pathway. The rod bipolars synapse directly onto type AII amacrine cells, but unlike other bipolars the rod bipolars do not synapse directly onto ganglion cells. The rod bipolars synapse on the AII amacrine cells within a narrow level of the inner plexiform layer. Finally, the AII amacrines synapse onto retinal ganglion cells both within the same level of the inner plexiform layer and also at a a second level of the inner plexiform layer. The ganglion cells that connect with the AII amacrine cells also receive signals via a cone-initiated pathway. Hence, the rod pathway merges with a cone-initiated pathway and disappears as a unique entity at this point.</p>
<p>By examining the properties of the rod pathway, we can see certain general features that might also be true of the organization of other visual pathways. First, the rod pathway only exists over a few synapses, serving its function and then merging with the main visual signal. By converging onto the main processing stream, central processing elements that define shape, form, and so forth can analyze both the rod and cone signals and need not be duplicated. Thus, a visual pathway may serve its purpose within a few synapses and then disappear.</p>
<p>Second, we see that visual streams may be created to serve fairly rudimentary functions, such as enhancing some aspect of the information in the image. The strong convergence of signals within the rod pathway — a single rod bipolar may integrate the signal from 1500 rods — makes the rod pathway well-suited to capturing information at low light levels while paying a penalty in terms of visual acuity. Hence, visual pathways may be created to achieve a special computational goal.</p>
<p>There are probably many types of information, in addition to the illumination level, that are formed for special computational purposes. For example, some types of behaviors may require precise visual information of one sort; say, to track a moving object. To improve this type of performance, one may require a pathway with excellent temporal resolution. Other behaviors may require precise visual information of another sort; say, to identify a texture pattern may require high spatial acuity. This might require a pathway with very high spatial sampling resolution. <span class="citation" data-cites="rodieck1993-pathways">Rodieck, Brening, and Watanabe (<a href="#ref-rodieck1993-pathways" role="doc-biblioref">1993</a>)</span> estimate that there may be as many as twenty pathways originating within the retina, and that each of these pathways communicates its signal to a different location in the central nervous system. Like the rods and cones, each subcategory of retinal ganglion cell obtains a fairly complete copy of the retinal image. We may presume that each subcategory of ganglion cell type specializes in communicating about certain types of visual information.</p>
<p>We will refer to the connected series of neurons carrying information in parallel as <em>visual streams</em> or <em>visual pathways</em>. The precise site where information is segregated into different visual streams within the retina is not certain, but it seems likely that the segregation begins immediately at the output of the rods and cones. In fact, there appear to be about 15 to 20 different bipolars that make contact with each cone. The information encoded by each of the bipolars may serve as the starting point for the visual streams that have been identified at points further along the visual pathway (<span class="citation" data-cites="rodieck1993-pathways">Rodieck, Brening, and Watanabe (<a href="#ref-rodieck1993-pathways" role="doc-biblioref">1993</a>)</span>; <span class="citation" data-cites="boycott-wassle-1991">Wässle and Boycott (<a href="#ref-boycott-wassle-1991" role="doc-biblioref">1991</a>)</span>).</p>
<!-- %Morphological classif of bipolar cells of the primate retina -->
<p>Evidently, one of the important functions of the retina is to organize the information encoded by the photoreceptors into a collection of visual streams. Presumably, the purpose of these separate visual streams is to communicate relevant image information efficiently to brain areas engaged in specialized types of visual processing. This observation reinforces the view that the existence of these visual streams can be an important clue about the functional organization of the visual pathways. We presume that each visual stream carries an efficient representation of the spatio-temporal component of the image that is most relevant for task carried out in visual area where the ganglion cell output is sent. Hence, by studying the response sensitivity to different kinds of stimuli of the neurons within a visual stream, we learn something about the functional role of that stream.</p>
</section>
<section id="retinal-function-image-contrast-and-adaptation" class="level3" data-number="5.1.3">
<h3 data-number="5.1.3" class="anchored" data-anchor-id="retinal-function-image-contrast-and-adaptation"><span class="header-section-number">5.1.3</span> Retinal function: image contrast and adaptation</h3>
<p>There are some visual challenges that are common to the information carried on all of the specialized visual streams. It makes sense to try to solve these types of problems when the signals are close together, as in the retina, rather than after the visual signals have reached widely separated destinations within the brain.</p>
<p>A fundamental challenge that is common to the signals carried by all retinal neurons is this: they must remain sensitive as the ambient light intensity varies over many orders of magnitude. This is a challenge for the nervous system because neurons have a very limited response range.</p>
<p>Neurons in the peripheral visual system solve this problem, in part, by signaling the local contrast in the image rather than the absolute stimulus level. The local contrast is the percent change in the image intensity relative to the local average. The range of contrasts in a typical image is constant as ambient illumination level changes and typically spans no more than two orders of magnitude. By coding contrast, rather than absolute level, neurons with small dynamic range can convey essential information about the retinal image despite enormous variations in the absolute level. In later chapters we will review computational issues and we will find that in contrast is an important signal in its own right. The contrast signal is closely coupled to the properties of surfaces, and surfaces are often the visual entity we want to identify or recognize<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
</section>
</section>
<section id="visual-streams" class="level2 page-columns page-full" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="visual-streams"><span class="header-section-number">5.2</span> Visual Streams</h2>
<p>We will begin by reviewing the kinds of methods we can use to classify retinal neurons. Then, we will review the principal features of the information carried within two specific visual streams, the <em>parvocellular pathway</em> and the <em>magnocellular pathway</em>. We focus on these two streams because we know most about them and because their output represents a very large fraction of the total output of the retina.</p>
<section id="methods-of-classifying-neurons" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="methods-of-classifying-neurons"><span class="header-section-number">5.2.1</span> Methods of classifying neurons</h3>
<p>The form and structure of a neuron, including its dendritic field, cell body, and axonal projections, are called the neuron’s <em>morphology</em>, The most fundamental method of distinguishing categories of neurons is simply to study their morphology. A second type of data we can use is the neuron’s electrical responsiveness to different signals, that is its <em>electrophysiology</em>. A third type of data we can use is to study the chemical substances used to build the neuron, that is the neuron’s <em>biochemistry</em>. A fourth type of data is the <em>anatomical</em> pattern of interconnections a neuron makes with other neurons. The most satisfying classification of neurons occurs when the evidence from these different sources converge.</p>
<p>We used all of these methods to distinguish the photoreceptors into rods and cones. The rods and cones can be classified based on their morphology of the cell (rod-like shape versus cone-like shape), the type of photopigment they contain, their electrical response to light, and their interconnections (rods make no connections in the fovea). Taken together, the classification of rods and cones also suggests a difference in function, namely that cones carry visual information used for high acuity tasks and rods are specialized for low illumination conditions.</p>
<p>It is natural to use our successes at peripheral levels to guide our next analysis of cellular function. So, we begin the analysis of the retinal ganglion cells by considering how we can use the measurements to categorize the retinal ganglion cells into groups serving various visual functions.</p>
</section>
<section id="morphology-of-parasol-and-midget-ganglion-cells" class="level3 page-columns page-full" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="morphology-of-parasol-and-midget-ganglion-cells"><span class="header-section-number">5.2.2</span> Morphology of Parasol and Midget Ganglion Cells</h3>
<p>When examining the retinal ganglion cell layer using a light microscope, one sees ganglion cells of many different sizes, shapes and patterns of dendritic fields. In an extraordinary set of studies, Santiago Ramon y Cajal examined the retinal cell types in many mammalian eyes, but no primates, and identified the basic anatomical structure of the retina. To classify neurons, Cajal used several morphological properties, relying mainly on the location of the dendritic arbor terminations. <a href="#fig-cajal" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-cajal</span></a> shows Cajal at work, along with one of his sketches of the mammalian retina.</p>
<div id="fig-cajal" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-cajal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/cajal-lab-drawing.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-cajal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.5: Ramon y Cajal and one of his drawings. Cajal is shown at his lab bench along with a drawing he made of the direction of visual signals in a mammalian retina. The labeled cells in part A of Cajal’s drawings are (a) rod bipolar, (b) cone bipolar, (c) and (d) ganglion cells. The connections with a subcortical visual center are shown in part B (Source: <span class="citation" data-cites="popova-cajal2017">Popova (<a href="#ref-popova-cajal2017" role="doc-biblioref">2017</a>)</span> and <span class="citation" data-cites="reichenbach-cajaldrawings2022">Reichenbach and Bringmann (<a href="#ref-reichenbach-cajaldrawings2022" role="doc-biblioref">2022</a>)</span>).
</figcaption>
</figure>
</div>
<p>The modern era of anatomical studies in the primate retina began with the work of Stephen Polyak (<span class="citation" data-cites="polyak1941-retinabook">S. L. Polyak (<a href="#ref-polyak1941-retinabook" role="doc-biblioref">1941</a>)</span>; <span class="citation" data-cites="polyak1957-vertebratebook">S. L. Polyak (<a href="#ref-polyak1957-vertebratebook" role="doc-biblioref">1957</a>)</span>) who wrote a remarkable pair of books describing his investigations into the primate visual system. Polyak described many aspects of the anatomical structure of the retina specifically and the primate vertebrate visual system generally. In his work on the retinal ganglion cells, Polyak identified five different categories of cells using the size of their cell bodies and the properties of their dendritic fields. One of the principal classifications he made, and the one that will concern us here, was based on the size and spread of the retinal ganglion cell dendritic arborizations. At most locations within the retina one can identify some neurons whose dendritic fields are relatively dense and compact compared to other retinal ganglion cells. Near the fovea these neurons are particularly conspicuous since they make contact with only a single bipolar which in turn makes contact with only a single cone. Polyak was the first to identify these retinal ganglion cells which are abundant in the primate but absent in other mammals. Polyak named these cells <em>midget</em> ganglion cells. Several midget ganglion cells at different positions within the retina are illustrated in <a href="#fig-midget-parasol" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-midget-parasol</span></a> (a).</p>
<div id="fig-midget-parasol" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-midget-parasol-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/midgetParasol.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-midget-parasol-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.6: A comparison of midget and parasol retinal ganglion cell morphology at various retinal eccentricities. (a) Midget ganglion cells and (b) parasol ganglion cells from a series of positions within the retina are shown as camera lucida drawings. At comparable positions within the retina, the dendritic tree of the midget ganglion cell is smaller and denser than that of the parasol cell. For both types of cells, however, the absolute size of the dendritic field increases with eccentricity. (Source: <span class="citation" data-cites="watanabe-rodieck1989">Watanabe and Rodieck (<a href="#ref-watanabe-rodieck1989" role="doc-biblioref">1989</a>)</span>).
</figcaption>
</figure>
</div>
<p>The morphology of the midget ganglion cells contrasts with a second class of ganglion cells shown in <a href="#fig-midget-parasol" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-midget-parasol</span></a> (b) and called <em>parasol</em> cells by Polyak. The parasol cells have a sparse dendritic tree and medium to large cell bodies. The drawings in <a href="#fig-midget-parasol" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-midget-parasol</span></a> compare a sampling of the midget and parasol cells at several distances from the fovea.</p>
</section>
<section id="variation-with-retinal-eccentricity" class="level3 page-columns page-full" data-number="5.2.3">
<h3 data-number="5.2.3" class="anchored" data-anchor-id="variation-with-retinal-eccentricity"><span class="header-section-number">5.2.3</span> Variation with retinal eccentricity</h3>
<p>As Polyak noted, the size of many types of retinal neurons increases with distance from the fovea. For example, a cell body or dendritic field that is relatively large in the fovea will be relatively small in the periphery. While Polyak says that the midget ganglion cells are present throughout the retina, due to retinal inhomogeneity the midget ganglion cells in the periphery are larger than the parasol cells near the fovea. If absolute size is not a reliable indicator, what measurement can we use to decide whether neurons at different eccentricities are of the same type? In a seminal paper, <span class="citation" data-cites="boycott-wassle1974-rgctypescat">Boycott and Wässle (<a href="#ref-boycott-wassle1974-rgctypescat" role="doc-biblioref">1974</a>)</span> showed how to make such a measurement in the retina of the domestic cat. The idea is simple and elegant: make measurements that span a wide range of retinal eccentricities and compare the trends within the population. Boycott and Wässle’s methods and observations have been extended from cat to the primate and human (<span class="citation" data-cites="perry1981-xyganglion">Perry and Cowey (<a href="#ref-perry1981-xyganglion" role="doc-biblioref">1981</a>)</span>, <span class="citation" data-cites="perry1984-rgcsupcolliculus">Perry and Cowey (<a href="#ref-perry1984-rgcsupcolliculus" role="doc-biblioref">1984</a>)</span>; <span class="citation" data-cites="levinthal1981">Levinthal, Rodieck, and Dreher (<a href="#ref-levinthal1981" role="doc-biblioref">1981</a>)</span>; <span class="citation" data-cites="rodieck1985-pmganglion">Rodieck, Binmoeller, and Dineen (<a href="#ref-rodieck1985-pmganglion" role="doc-biblioref">1985</a>)</span>; <span class="citation" data-cites="watanabe-rodieck1989">Watanabe and Rodieck (<a href="#ref-watanabe-rodieck1989" role="doc-biblioref">1989</a>)</span>; <span class="citation" data-cites="dacey1992-mpganglion">D. M. Dacey and Petersen (<a href="#ref-dacey1992-mpganglion" role="doc-biblioref">1992</a>)</span>).</p>
<p><a href="#fig-dend-field-ecc" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-dend-field-ecc</span></a> shows that the size of dendritic fields of the midget and parasol ganglion cells increase with eccentricity in the human retina. Although both cell types increase in size, within each cell type the dendritic field size varies smoothly and at each retinal eccentricity the sizes of the two populations remain distinct. The graph in <a href="#fig-dend-field-ecc" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-dend-field-ecc</span></a> suggests that the signals from the midget cells form one unified visual stream and the parasol cells form a second visual stream (<span class="citation" data-cites="dacey1992-mpganglion">D. M. Dacey and Petersen (<a href="#ref-dacey1992-mpganglion" role="doc-biblioref">1992</a>)</span>).</p>
<div id="fig-dend-field-ecc" class="quarto-figure align-center quarto-float quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-dend-field-ecc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/dendFieldEcc.png" class="quarto-figure align-center img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-dend-field-ecc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.7: Dendritic field size as a function of eccentricity in the human retina. The graph shows the dendritic field size of midget and parasol neurons. The dendritic field size increases with eccentricity for both types of neurons, but at each eccentricity the sizes are easily classified. (Source: <span class="citation" data-cites="dacey1992-mpganglion">D. M. Dacey and Petersen (<a href="#ref-dacey1992-mpganglion" role="doc-biblioref">1992</a>)</span>).
</figcaption>
</figure>
</div>
<p>Further evidence that these two classes of neurons form independent visual streams comes from their coverage of the retinal image. Both midget and parasol cells are present at every location within the retina. Thus, each class of neuron encodes a complete copy of the retinal image.</p>
<p>Although the two populations both receive a complete copy of the image, they do not encode the image at the same spatial resolution. In the fovea, midget ganglion cells receive input from a single cone (N.B. This does not mean that a cone sends its output to a single bipolar or ganglion!). From the spread of their dendritic fields, we see that the parasol cells receive convergent input from a much wider area of the retina. The fine resolution achieved by the midget ganglion cells means that more of them than parasol cells are needed to encode the entire retinal image. There appear to be 7 or 9 times as many midget cells as parasol cells (<span class="citation" data-cites="sterling1994">Sterling et al. (<a href="#ref-sterling1994" role="doc-biblioref">1994</a>)</span>; <span class="citation" data-cites="perry1984-dorsallgn">Perry, Oehler, and Cowey (<a href="#ref-perry1984-dorsallgn" role="doc-biblioref">1984</a>)</span>). The midget ganglion cells encode the spatial image up to the full sampling resolution of the photoreceptors, roughly 60 cycles per degree. The smaller number of parasol cells are capable of encoding the signal up to a spatial resolution of 20 cycles per degree.</p>
<div id="fig-rgc-maps" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-rgc-maps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/rgcMaps.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-rgc-maps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.8: Midget and parasol dendritic fields both sample the entire retinal image. The dendritic fields of the midget ganglion cells (a) are small compared to the dendritic fields of the parasol cells (b). Parasol cells have much larger dendritic fields at each retinal location, so that fewer are needed to cover the entire retina (From <span class="citation" data-cites="watanabe-rodieck1989">Watanabe and Rodieck (<a href="#ref-watanabe-rodieck1989" role="doc-biblioref">1989</a>)</span>).
</figcaption>
</figure>
</div>
</section>
<section id="central-projections" class="level3 page-columns page-full" data-number="5.2.4">
<h3 data-number="5.2.4" class="anchored" data-anchor-id="central-projections"><span class="header-section-number">5.2.4</span> Central Projections</h3>
<p>A second method of identifying visual streams originating in the ganglion cell layers is to consider how the retinal ganglion By injecting tracer substances that are carried from the brain back to the retina, we can identify where each type of retinal ganglion cell sends its outputs.</p>
<p><span class="citation" data-cites="perry1984-dorsallgn">Perry, Oehler, and Cowey (<a href="#ref-perry1984-dorsallgn" role="doc-biblioref">1984</a>)</span> studied how different cell types send their axons to brain structures. They injected a tracer substance called <em>horseradish peroxidase</em> into the optic nerve. When horseradish peroxidase is absorbed by a neuron, it is transported throughout the neuron. Thus, if the horseradish peroxidase is absorbed in an axon, it is transported back to the cell body. Conversely if the horseradish peroxidase is absorbed in the cell body, it will be transported down to the axon terminals. The presence of horseradish peroxidase within a neuron can be established by appropriate histochemistry. By injecting the tracer into the optic nerve, they could identify the appearance of all cell types when stained by horseradish peroxidase.</p>
<p><span class="citation" data-cites="perry1984-dorsallgn">Perry, Oehler, and Cowey (<a href="#ref-perry1984-dorsallgn" role="doc-biblioref">1984</a>)</span> also introduced horseradish peroxidase into the lateral geniculate, a nucleus located in the <em>thalamus</em>, that is a major recipient of axons from the retina. The majority of the retinal ganglion cells make a connection with this nucleus, so that the horseradish peroxidase was transported to many retinal ganglion cells. They estimate that 90 percent of monkey retinal ganglion cells send their axons to the lateral geniculate layers. While the preponderance of retinal ganglion cells containing horseradish peroxidase could be classified as either parasol or midget, there is some evidence that at least two other types of retinal ganglion cells also send their outputs to the lateral geniculate nucleus (<span class="citation" data-cites="rodieck1993-pathways">Rodieck, Brening, and Watanabe (<a href="#ref-rodieck1993-pathways" role="doc-biblioref">1993</a>)</span>).</p>
<div id="fig-lgn" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-lgn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/lgn-updated2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-lgn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.9: The lateral geniculate nucleus (LGN) is located in the thalamus. In primates, most retinal ganglion cell axons terminate in the LGN. Using a Golgi stain, the LGN shows six distinct layers: the four upper layers are the <strong>parvocellular layers (P)</strong>, which contain small cell bodies and receive input mainly from midget ganglion cells; the two lower layers are the <strong>magnocellular layers (M)</strong>, which contain large cell bodies and receive input mainly from parasol ganglion cells. Each layer receives input from only one eye—either the same side (I, ipsilateral) or the opposite side (C, contralateral). Neurons are also found between these layers in regions called intercalated zones, which require specialized markers to visualize. (Adapted from <span class="citation" data-cites="andrews1997-lgn">Andrews, Halpern, and Purves (<a href="#ref-andrews1997-lgn" role="doc-biblioref">1997</a>)</span>)
</figcaption>
</figure>
</div>
<p>There is considerable regularity in the distribution of axons from the parasol and midget neurons within the primate lateral geniculate nucleus. The primate lateral geniculate nucleus contains six different layers (see <a href="#fig-lgn" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-lgn</span></a>). The four superficial layers contain neurons with small cell bodies and are called the <em>parvocellular layers</em>. The two deeper layers contain neurons with large cell bodies and are called the <em>magnocellular layers</em>. The axons of parasol and midget retinal ganglion cells make connections in different layers of the lateral geniculate nucleus. The axons of the midget retinal ganglion cells terminate in the parvocellular layers, while the axons of the parasol cells terminate in the magnocellular layers. In addition to the cell bodies within parvocellular and magnocellular layers, there are also cell bodies that fall in between in regions called the <em>intercalated zones</em>. These zones may receive signals from yet another class of retinal ganglion cells.</p>
<p>The consistency in the shape of the cells and their central projections suggests that the midget and parasol cells form separate visual streams. The pathway that begins with the midget ganglion cells and terminate within the parvocellular layers of the lateral geniculate nucleus is called the <em>parvocellular pathway</em>, while the pathway that begins within the parasol cells and terminate within the magnocellular layers of the lateral geniculate is called the <em>magnocellular pathway</em>. The significance of these pathways for visual perception is the source of much current experiment and speculation. How far within the visual pathways are these signals segregated? Do the signals on these pathways carry information with different and specialized perceptual significance? In the next sections I will review some of the differences in how these neurons respond to light. I will discuss experiments that address the broader topic of the perceptual significance of these pathways at several points throughout the book.</p>
<p>Although the majority of retinal ganglion cells send their outputs to the lateral geniculate, there are many other destinations for the optic tract fibers. For example, <span class="citation" data-cites="perry1980-fovea">Perry and Cowey (<a href="#ref-perry1980-fovea" role="doc-biblioref">1980</a>)</span> introduced horseradish peroxidase into the monkey superior colliculus a nucleus in the <em>mid-brain</em> that is known to receive input from retinal ganglion cells. They found that about ten percent of the retinal ganglion cells send axons that terminate in the superior colliculus. None of the labeled cells were midget or parasol ganglion cells. <span class="citation" data-cites="rodieck1993-pathways">Rodieck, Brening, and Watanabe (<a href="#ref-rodieck1993-pathways" role="doc-biblioref">1993</a>)</span> review a broad range of measurements concerning visual streams of retinal origin. They conclude that each subcategory of ganglion cell sends its output to a single destination in the brain, making the morphology of retinal ganglion cells a very important clue in determining the organization of the visual streams that originate in the retina.</p>
<p>The majority of the retinal output is sent to the lateral geniculate nucleus. But, the retinal connections in the lateral geniculate nucleus account for only about 10 percent of the synapses. Nearly 60 percent of the synapses in the lateral geniculate are signals from the cortex and the remaining synapses are connections with other parts of the brain (<span class="citation" data-cites="sherman-koch1990">Sherman and Koch (<a href="#ref-sherman-koch1990" role="doc-biblioref">1990</a>)</span>).</p>
</section>
<section id="conduction-time-and-contrast-gain" class="level3 page-columns page-full" data-number="5.2.5">
<h3 data-number="5.2.5" class="anchored" data-anchor-id="conduction-time-and-contrast-gain"><span class="header-section-number">5.2.5</span> Conduction Time and Contrast Gain</h3>
<p>There are several differences in the way neurons in the parvo- and magnocellular pathways code information. These differences are clues about the kind of visual information represented by these visual streams and the function these streams serve in vision.</p>
<p>First, the conduction time for electrical signals traveling from the optic chiasm to the parvocellular layers of the lateral geniculate nucleus is longer than the conduction time to the magnocellular neurons. <span class="citation" data-cites="schiller1978-lgn">P. H. Schiller and Malpeli (<a href="#ref-schiller1978-lgn" role="doc-biblioref">1978</a>)</span> measured the conduction time for an electrical stimulus originating in the optic chiasm to travel to different layers in the lateral geniculate nucleus. The signal arrives later in the parvocellular layers than it does in the magnocellular layers, as illustrated by the histograms in <a href="#fig-conduction" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-conduction</span></a>.</p>
<div id="fig-conduction" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-conduction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/conduction.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-conduction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.10: The conduction time for an electrical stimulus to travel from the optic chiasm to the magnocellular and parvocellular layers of the lateral geniculate. The responses of neurons in the parvocellular layers (a) are delayed compared to the responses of neurons in the magnocellular layers (Source: <span class="citation" data-cites="schiller1978-lgn">P. H. Schiller and Malpeli (<a href="#ref-schiller1978-lgn" role="doc-biblioref">1978</a>)</span>).
</figcaption>
</figure>
</div>
<p>Second, the response of neurons in these two pathways to contrast patterns differs reliably. <span class="citation" data-cites="kaplan-shapley1982-xycells">Kaplan and Shapley (<a href="#ref-kaplan-shapley1982-xycells" role="doc-biblioref">1982</a>)</span> and <span class="citation" data-cites="kaplan-shapley1986-typesrgc">Kaplan and Shapley (<a href="#ref-kaplan-shapley1986-typesrgc" role="doc-biblioref">1986</a>)</span> observed that as the stimulus contrast of a sinusoidal grating pattern increases, the response of neurons in the magnocellular pathway changes more rapidly than neurons in the parvocellular pathway. <a href="#fig-pm-contrast" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-pm-contrast</span></a> compares the <em>contrast-response curves</em> of a neuron in the parvocellular pathway and a neuron in the magnocellular pathway. The horizontal axis measures the stimulus contrast and the vertical axis measures the neuron’s response as a percent change from the spontaneous response level. The contrast-response curve of the neuron in the magnocellular pathway increases more rapidly with stimulus contrast and also saturates at a lower contrast. The slope of the contrast-response curve is called the neuron’s <em>contrast-gain</em>. We can summarize the results in <a href="#fig-pm-contrast" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-pm-contrast</span></a> by saying that magnocellular neurons have higher contrast-gain than parvocellular neurons; the contrast-gain ratio is approximately eight.</p>
<div id="fig-pm-contrast" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-pm-contrast-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/pmContrast.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-pm-contrast-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.11: Contrast-response functions of neurons in the lateral geniculate nucleus. The contrast-responses of magnocellular neurons (filled squares) increase more rapidly than the contrast-responses of parvocellular neurons. (Source: <span class="citation" data-cites="shapley1986-parallel">Shapley (<a href="#ref-shapley1986-parallel" role="doc-biblioref">1990</a>)</span>)
</figcaption>
</figure>
</div>
<p>While they original observed the difference in contrast-gain in the lateral geniculate nucleus, Kaplan and Shapley went on to show that this difference can be traced to differences in the response gains of the midget and parasol neurons within the primate retina. Quite possibly, the differences in these signals may begin at the bipolar connection to the cones themselves.</p>
</section>
<section id="visual-information-encoded-by-the-parvocellular-and-magnocellular-pathways" class="level3 page-columns page-full" data-number="5.2.6">
<h3 data-number="5.2.6" class="anchored" data-anchor-id="visual-information-encoded-by-the-parvocellular-and-magnocellular-pathways"><span class="header-section-number">5.2.6</span> Visual Information Encoded by the Parvocellular and Magnocellular Pathways</h3>
<p>Anatomical and physiological measurements suggest that the parvocellular and magnocellular pathways carry different types of information to the brain. We can try to evaluate this hypothesis by removing one of the pathways by introducing a lesion in to the pathway and studying the changes in an animal’s performance due to the lesion.</p>
<p>When we perform a lesion, we must be careful not to damage fibers that are merely passing by, or else we will have lesioned remote sites that are the source or destination of the fibers. The substance <em>ibotenic acid</em> is particularly useful for lesion studies because it destroys cell bodies of neurons but spares axons. Ibotenic acid has been applied to lesion neurons in the magnocellular or parvocellular layers. By studying changes in performance after ibotenic lesions of the parvocellular and magnocellular pathways, we learn something about the information present on these two visual streams (<span class="citation" data-cites="schiller1990-channels">P. H. Schiller and Logothetis (<a href="#ref-schiller1990-channels" role="doc-biblioref">1990</a>)</span>; <span class="citation" data-cites="merigan1991a-primatemotion">W. H. Merigan, Byrne, and Maunsell (<a href="#ref-merigan1991a-primatemotion" role="doc-biblioref">1991</a>)</span>, <span class="citation" data-cites="merigan1991b-plgnlesion">W. H. Merigan, Katz, and Maunsell (<a href="#ref-merigan1991b-plgnlesion" role="doc-biblioref">1991</a>)</span>; <span class="citation" data-cites="lynch1992">Lynch et al. (<a href="#ref-lynch1992" role="doc-biblioref">1992</a>)</span>).</p>
<p>When cells in the parvocellular layers of a monkey’s lateral geniculate nucleus are destroyed, performance deteriorates on a variety of tasks, such as color discrimination and pattern detection. Since the parvocellular pathway includes more than seventy percent of the retinal ganglion cells, perhaps this result is not terribly surprising. When cell bodies in the magnocellular layers are destroyed many visual performances are unaffected. The results of several behavioral measurements before and after these lesions are summarized in <a href="#fig-pm-lesion" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-pm-lesion</span></a> (<span class="citation" data-cites="merigan1991a-primatemotion">W. H. Merigan, Byrne, and Maunsell (<a href="#ref-merigan1991a-primatemotion" role="doc-biblioref">1991</a>)</span>).</p>
<p>The most informative result is this: when neurons in the magnocellular layers are destroyed, the animal is less sensitive to rapidly flickering low spatial frequency targets. This loss of sensitivity shows that the magnocellular pathway contains the best information about this aspect of the image. This suggests that the magnocellular pathway is a specialization that improves our ability to perform tasks requiring high temporal frequency information.</p>
<p>What type behaviors depend on the low spatial frequency and high temporal frequency information represented by the magnocellular pathway? Two examples of visual tasks that require precise and rapid information about rapidly varying image signals are motion detection and motion-tracking. The central projections of the magnocellular pathway we will review later, coupled with the significance of the perceptual signals, suggest that the magnocellular pathway plays an important role in providing high quality information used in motion perception.</p>
<p>What conclusion can we draw from these lesion studies? The information carried by the neurons in the magnocellular pathway provide the <em>best</em> information in the low temporal and high spatial frequency components of the image. Performance on motion tasks and other tasks that require this information is better when the magnocellular pathway signal is available. The signals are not absolutely necessary to perform the task. This was shown by <span class="citation" data-cites="merigan1991a-primatemotion">W. H. Merigan, Byrne, and Maunsell (<a href="#ref-merigan1991a-primatemotion" role="doc-biblioref">1991</a>)</span>, who studied motion perception in monkeys with magnocellular pathway lesions. They found that performance deficits on motion tasks could be compensated for simply by increasing the stimulus contrast; that is, one can compensate for the loss of information on the magnocellular pathway by improving the quality of the information on the parvocellular pathway. Hence, the magnocellular pathway contains information that is particularly useful for certain kinds visual tasks, such as motion perception. Discovering where these signals are sent in the central brain should provide us with some useful ideas about where we compute and perceive motion, as well as other visual tasks requiring this type of information.</p>
<div id="fig-pm-lesion" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-pm-lesion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/pmLesion.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-pm-lesion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.12: The effect of lesions in the parvocellular and magnocellular layers of the monkey lateral geniculate nucleus. (a)~The smooth curve defines the control monkey’s performance when detecting a stationary grating. Filled circles show performance following lesion of the magnocellular pathway. Open squares show performance following lesion of the parvocellular pathway. (b)~The smooth curve defines the control monkey’s performance when detecting a low spatial frequency target at various flicker rates. Filled circles show performance following lesion of the magnocellular pathway and open squares show performance following lesion of the parvocellular pathway. (c)~Comparison of sensitivity in detecting color contrast in the control and lesion conditions. (Source: <span class="citation" data-cites="merigan1993-parallelprimatevisual">W. H. Merigan and Maunsell (<a href="#ref-merigan1993-parallelprimatevisual" role="doc-biblioref">1993</a>)</span>)
</figcaption>
</figure>
</div>
</section>
</section>
<section id="retinal-ganglion-cell-response-to-light" class="level2 page-columns page-full" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="retinal-ganglion-cell-response-to-light"><span class="header-section-number">5.3</span> Retinal Ganglion Cell Response To Light</h2>
<p>The output of the retinal ganglion cells consists of a series of discrete electrical impulses called <em>action potentials</em> or <em>spikes</em>. We measure ganglion cell responses by recording the temporal pattern of action potentials caused by light stimulation. Retinal ganglion cells form part of a pathway that transforms the light into a temporal series of electrical pulses. The properties of the neural transformation from a light signal to a pattern of action potentials is one of the main types of evidence we have about a neuron’s functional significance, and hence the pathway’s role in vision.</p>
<p>Within the field of <em>electrophysiology</em>, the field that studies the electrical response of neurons, the transformation associated with a neuron is called the neuron’s <em>receptive field</em>. The receptive field concept, first used in vision by <span class="citation" data-cites="hartline1938-illumination">Hartline (<a href="#ref-hartline1938-illumination" role="doc-biblioref">1938</a>)</span>, is a cornerstone of the electrophysiolgist’s description of the action of visual neurons. The receptive field concept, like the notion of a transformation is quite general. Hence, the receptive field notion is used also to describe neural properties in other sensory and motor areas as well (<span class="citation" data-cites="mountcastle1957-modality">Mountcastle (<a href="#ref-mountcastle1957-modality" role="doc-biblioref">1957</a>)</span>).</p>
<p>Classically, the visual receptive field of a neuron was defined as the retinal area in which light influences the neuron’s response. This region can be defined by positioning small flashes of light and simple moving bars and evaluating when the neuron responds and fails to respond. The responses of many neurons in the visual pathway are influenced only by light falling within narrow regions of the retina, and hence small regions of the visual field. The region of the visual field in which these flashes of light and bars influence the neuron’s response is called the neuron’s classically-defined receptive field. This description is relatively easy to obtain and provides a useful preliminary description of the neuron’s transformation.</p>
<p>Although we refer to a <em>neuron’s</em> receptive field, in fact the receptive field depends on the properties of the entire visual pathway, beginning with the optics and including the transformation by the neuron itself. In some cases, when there is feedback descending upon the neuron from central brain regions, the receptive field we measure at a neuron includes contributions from many places within the visual pathways (though there is no feedback to the retinal ganglion cells).</p>
<section id="center-surround-organization" class="level3 page-columns page-full" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="center-surround-organization"><span class="header-section-number">5.3.1</span> Center-Surround Organization</h3>
<div id="fig-rgc-recording" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-rgc-recording-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/rgc.recording.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="452">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-rgc-recording-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.13: Retinal ganglion cell action potentials can be recorded with a microelectrode at the two locations shown. One location is near the cell bodies in the ganglion cell layer of the retina. A second position is near the optic nerve (Source: <span class="citation" data-cites="enroth-cugell1984-diversity">C. Enroth-Cugell and Robson (<a href="#ref-enroth-cugell1984-diversity" role="doc-biblioref">1984</a>)</span>).
</figcaption>
</figure>
</div>
<p>Several important properties of ganglion cell receptive fields were discovered by measuring the classically defined receptive field. In this section we will consider how one important property, <em>center-surround</em> organization, was measured.</p>
<p>There are two locations in the visual pathways where one can conveniently record the spiking activity of retinal ganglion cells (see <a href="#fig-rgc-recording" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-rgc-recording</span></a>). One can measure the electrical activity from the cell bodies of the retinal ganglion cells, which are on the surface of the retina closest to the cornea, or one can insert the microelectrode in the optic nerve which contains the axonal fibers that emerge from the cell bodies and carry the signal to the cortex. When the electrode is positioned properly with respect to the cell body of a neuron, or an axon in the optic nerve, we can record action potentials.</p>
<p>When the stimulus is a large uniform field, most retinal ganglion cells respond with a random stream of action potentials. A typical retinal ganglion cell response to uniform illumination might consist of 50 spikes per second. For most retinal ganglion cells, the temporal sequence of the spiking activity has no systematic temporal structure, so that the chance of a spike occurring in the next brief interval of time is approximately constant. We call the average number of action potentials per unit time, in the presence of a constant field, the <em>spontaneous firing rate</em> of the retinal ganglion cell.</p>
<div id="fig-center-surround" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-center-surround-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/center.surround.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-center-surround-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.14: The receptive field of mammalian retinal ganglion cells have a center-surround organization. In a small central region of the retina, light stimulation may excite or inhibit a neuron. In a surrounding annular region light stimulation will have an opposing effect to that of the center. The receptive field shown here has an on-center and an off-surround cell. (Source: <span class="citation" data-cites="kuffler1953-discharge">Kuffler (<a href="#ref-kuffler1953-discharge" role="doc-biblioref">1953</a>)</span>).
</figcaption>
</figure>
</div>
<p>S. Kuffler was the first to define the receptive field of of mammalian retinal ganglion cells. They used small points of light flashed at different retinal positions, and they recorded the difference between the spontaneous firing rate and the response when the point of light was presented at different points on the retinal surface. An example from Kuffler’s measurements is shown in <a href="#fig-center-surround" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-center-surround</span></a>. A small spot of light flashed within a central region of the receptive field causes an increase in firing relative to the spontaneous activity. When the spot is placed on a surrounding area, there is a measurable decrease in the cell’s activity. The intermediate region showed some excitation at the beginning of the stimulus and some inhibition at stimulus extinction (<span class="citation" data-cites="kuffler1953-discharge">Kuffler (<a href="#ref-kuffler1953-discharge" role="doc-biblioref">1953</a>)</span>; <span class="citation" data-cites="barlow1957-dark">Barlow, Fitzhugh, and Kuffler (<a href="#ref-barlow1957-dark" role="doc-biblioref">1957</a>)</span>).</p>
<p>The responses illustrated in <a href="#fig-center-surround" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-center-surround</span></a> define an <em>on-center, off-surround</em> receptive field. About half of the retinal ganglion cells respond this way. The remaining ganglion cells are inhibited by light falling on the center and excited by light falling on the surround. These are called <em>off-center, on-surround</em> cells. Most mammalian retinal ganglion cells exhibit the basic <em>center-surround</em> organization.</p>
<p>The dendritic fields of retinal ganglion cells with on-center are segregated in the inner plexiform layer of the retina from retinal ganglion cells with off-center receptive fields. Ganglion cells that make connections in the upper portion of the inner plexiform layer have an off-center, while neurons that synapse in the lower half of the inner plexiform layer have on-center receptive fields. Hence, the anatomy and electrophysiology suggest that there are at least two types of visual pathways, an on-center and an off-center pathway, emerging from the retina.</p>
<!-- %In the human retina, the receptive field sizes of on-center neurons appears to be somewhat larger than the receptive fields of off-center neurons (Nelson et al., 19XX). \\nocite{Nelson et al, Kolb …}  \\nocite{BoycottandWassleReviewArticle} \\nocite{Dacey1992} % and Petersen, PNAS -->
</section>
<section id="measurements-of-receptive-fields" class="level3 page-columns page-full" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="measurements-of-receptive-fields"><span class="header-section-number">5.3.2</span> Measurements of Receptive Fields</h3>
<p>The classical receptive field is only a partial description of the neuron’s response properties. To understand a neuron’s transformation of the light signal completely, we would like to predict the pattern of action potentials in response to any visual stimulus. To describe the transformation from light to neural activation completely, we need to develop a more systematic method of measuring the neuron’s response. Since there are many possible visual stimuli, we need to develop a method so that we can make a small set of measurements and then use these measurements to predict the responses to all other stimuli.</p>
<p>Linear systems theory provides some guidance on the question of how to measure the receptive field completely. If a neuron’s responses to light satisfies the principle of superposition, then we can use a few measurements to predict how the neuron will respond to many other visual stimuli. As we shall see, in the primate retina and lateral geniculate nucleus, linearity provides a satisfactory account of a large part of the neural response.</p>
<div id="fig-ec-pinto" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-ec-pinto-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/ec.pinto_.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-ec-pinto-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.15: A test of superposition of the response of a retinal ganglion cell. (a)~The PSTH to a disk of light flashed in the center of the receptive field. (b)~The PSTH to an annulus flashed in the surround of the receptive field. (c)~The PSTH to simultaneous presentation of the disk and the annulus. (d)~The sum of the responses in (a) and (b). (e)~A comparison of the predicted and observed response to the sum of the stimuli. (Source: <span class="citation" data-cites="enroth-cugell1970-summation">C. Enroth-Cugell and Pinto (<a href="#ref-enroth-cugell1970-summation" role="doc-biblioref">1970</a>)</span>).
</figcaption>
</figure>
</div>
<p>How do we test whether the input-output relationship of a retinal ganglion cell satisfies the principle of superposition? A simple and direct test, for one pair of stimuli, is shown in <a href="#fig-ec-pinto" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-ec-pinto</span></a>. In this study <span class="citation" data-cites="enroth-cugell1970-summation">C. Enroth-Cugell and Pinto (<a href="#ref-enroth-cugell1970-summation" role="doc-biblioref">1970</a>)</span> examined the center-surround antagonism of cat retinal ganglion cells. They studied the superposition of two stimuli: a spot placed in the center of the ganglion cell receptive field and an annulus placed in the antagonistic surround. The response to the spot is illustrated in part (a) of the figure and the response to the annulus is illustrated in part (b).</p>
<p>If the ganglion cell response obeys the principle of superposition, we should be able to predict the temporal response when we present the spot and the annulus together. The observed response and the predicted response are shown in panels (c) and (d) of the figure. They are compared in panel (e) of the figure. For this pair of stimuli, and this retinal ganglion cell, the principle of superposition predicts the neuron’s complete response very well.</p>
</section>
<section id="steady-state-measurements" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="steady-state-measurements"><span class="header-section-number">5.3.3</span> Steady-state Measurements</h3>
<p>To build a complete description of the neural response properties, we must include time in our characterization of the neuron’s receptive field. We will consider the full space-time receptive field later in this chapter. But, it is simpler to begin with an example in which we eliminate time as a variable; we will consider only the response after the stimulus has been presented for several seconds and the neuron’s response has stabilized. This asymptotic response is called the <em>steady-state</em> response of the neuron. By measuring the steady-state response of the neuron, we remove time as a factor in our analysis.</p>
<p>As in all cases of linear systems studies, we must specify both the input and output signals carefully. One of the important advances in recent years has been discovering insightful definitions for the input and output stimuli we use to measure the neurons receptive fields. Both of these definitions are based on the notion of <em>contrast</em>.</p>
</section>
<section id="the-stimulus." class="level3" data-number="5.3.4">
<h3 data-number="5.3.4" class="anchored" data-anchor-id="the-stimulus."><span class="header-section-number">5.3.4</span> The stimulus.</h3>
<p>We use a spatial image as the input stimulus. We will represent the spatial image as the sum of two components. One part is the average light level of the stimulus, and the second part is the variation of the intensity about the mean. The mean level of the stimulus is always a positive number. The variation around the average light level is the <em>stimulus contrast</em> pattern. The stimulus contrast contains both positive and negative values.</p>
<p>Consider the simple case of a one-dimensional stimulus that varies along one spatial dimension and is constant in the second dimension. We can specify the stimulus contrast with respect to a single spatial variable, say <span class="math inline">\(x\)</span>. The formula that relates the stimulus intensity to the mean background intensity and the stimulus contrast is</p>
<p><span id="eq-rf-contrast"><span class="math display">\[
I = [ 1 + c ]~\mu ,
\tag{5.1}\]</span></span></p>
<p>where <span class="math inline">\(I\)</span> is the stimulus intensity, <span class="math inline">\(\mu\)</span> is the mean background intensity, and <span class="math inline">\(c\)</span> is the stimulus contrast.</p>
</section>
<section id="the-response." class="level3" data-number="5.3.5">
<h3 data-number="5.3.5" class="anchored" data-anchor-id="the-response."><span class="header-section-number">5.3.5</span> The response.</h3>
<p>Suppose that a neuron’s spontaneous firing rate is <span class="math inline">\(r_0\)</span>. Now, suppose we introduce a contrast pattern, <span class="math inline">\(c\)</span>, and the neuron’s steady-state response becomes <span class="math inline">\(r\)</span> spikes per second. We define the change in the retinal ganglion cell rate of response, <span class="math inline">\(\Delta r = r - r_0\)</span>, as the neuron’s response. Thus, just as we consider the input to be the stimulus change from the mean background level, so too we consider the neuron’s output to be the change from the average spontaneous response of the neuron.</p>
</section>
</section>
<section id="testing-contrast-linearity." class="level2 page-columns page-full" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="testing-contrast-linearity."><span class="header-section-number">5.4</span> Testing contrast linearity.</h2>
<p>To test superposition, we must measure the response to two different contrast patterns and their sum. Suppose we use two contrast patterns, <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> and corresponding changes in the steady-state response of <span class="math inline">\(\Delta r_1\)</span> and <span class="math inline">\(\Delta r_2\)</span>. To test superposition we combine the two contrast patterns to form a new stimulus,</p>
<p><span id="eq-rf-superposition"><span class="math display">\[
[ 1 + c_1 + c_2 ]~\mu .
\tag{5.2}\]</span></span></p>
<p>We expect that the steady-state response to the new test pattern will be <span class="math inline">\(\Delta r_1 + \Delta r_2\)</span>. Be sure to compare <a href="#eq-rf-contrast" class="quarto-xref">Equation&nbsp;<span class="quarto-unresolved-ref">eq-rf-contrast</span></a> and <a href="#eq-rf-superposition" class="quarto-xref">Equation&nbsp;<span class="quarto-unresolved-ref">eq-rf-superposition</span></a>; the new stimulus pattern is formed by adding together the <strong>contrast terms</strong>, <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span>, not the two intensity patterns.</p>
<div id="fig-rf-linear" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-rf-linear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/rf.linear.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-rf-linear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.16: The steady-state contrast response of primate retinal ganglion cells are often linear. We can predict the response to contrast patterns by measuring the system-matrix that maps the stimulus contrast into the increased firing rate of the neuron. Since the change in firing rate is a single number, the system matrix is a row-vector. The entries of the system matrix define the one-dimensional, steady-state, receptive field of the neuron.
</figcaption>
</figure>
</div>
<p>If the change in the neuron’s response satisfies the principle of superposition, we can model the response to any contrast pattern by defining a system matrix that describes the neuron’s transformation, i.e., receptive field. The relationship between the contrast stimulus, the system matrix, and the response is shown in <a href="#fig-rf-linear" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-rf-linear</span></a>. We represent the one-dimensional stimulus contrast pattern as a column vector. The output is the retinal ganglion cell response. If the neuron is linear, there is a matrix that maps the input contrast vector to the neural response. The system matrix is a <span class="math inline">\(1 \times N\)</span> matrix <span class="math inline">\(\mathbf{R}\)</span> whose entries define the one-dimensional receptive field of the neuron. We can use the system matrix to predict how the neuron will respond to any one-dimensional contrast pattern. We say that the entries of the matrix <span class="math inline">\(\mathbf{R}\)</span> define the <em>linear, steady-state, receptive field</em> of the neuron.</p>
<p>By examining the matrix tableau, you can see that to estimate the entries of the system matrix we need to measure the response to a series of lines at different positions on the retina. The response to each line defines the corresponding entry in the system matrix. The curve in <a href="#fig-rf-linear" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-rf-linear</span></a> (b) is a graphical representation of the entries of the system matrix, that is, of the neuron’s one-dimensional receptive field.</p>
<section id="the-two-dimensional-receptive-field" class="level3 page-columns page-full" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="the-two-dimensional-receptive-field"><span class="header-section-number">5.4.1</span> The Two-Dimensional Receptive Field</h3>
<div id="fig-rf-2d" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-rf-2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/rf.2d.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-rf-2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.17: The two-dimensional steady-state receptive field of an on-center off-surround retinal ganglion cell is represented in two different ways. (a) A surface plot shows the spatial sensitivity by the height of the surface. The inhibitory surround covers a large area compared to the center, but its general effect on the neuron’s response is small compared to the center. (b) An image shows the spatial sensitivity of the receptive field by the image intensity. A light color denotes a retinal location where light excites the neuron, a dark color is a location where light inhibits the neuron, and gray locations are places where light has no influence on the neuron’s response.
</figcaption>
</figure>
</div>
<p>By measuring with points of light rather than lines, we can measure a two-dimensional steady-state receptive field. <a href="#fig-rf-2d" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-rf-2d</span></a> shows two ways to represent the two-dimensional receptive field of a retinal ganglion cell. The height of the curve in <a href="#fig-rf-2d" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-rf-2d</span></a> (a) shows change neuron’s light response as we stimulate with a point of light at different locations in the visual field. The large positive values in the center of the diagram indicate that this neuron is excited by stimuli in a central region. The negative values in the surrounding region show the inhibition by point stimuli surrounding the central region. Notice that the effect at each point in the inhibitory surround is very small, but the inhibitory surround covers large area compared to the excitatory center. The picture captures quantitatively the center-surround antagonism that Kuffler discovered in cat retinal ganglion cells. <a href="#fig-rf-2d" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-rf-2d</span></a> (b) represents the same measurements as an image. Light regions show where the neuron is excited by a spot and a dark regions show where the neuron is inhibited.</p>
</section>
<section id="contrast-sensitivity-functions" class="level3 page-columns page-full" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="contrast-sensitivity-functions"><span class="header-section-number">5.4.2</span> Contrast Sensitivity Functions</h3>
<p>Often, it is useful to characterize the response of a linear system in terms of the system’s response to harmonic functions. It is helpful to understand the information encoded by neurons by plotting their response to harmonic functions as well.</p>
<div id="fig-rf-freq" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-rf-freq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/rf.freq_.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-rf-freq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.18: The contrast sensitivity function describes a neuron’s sensitivity to harmonic stimuli. In the example illustrated, a linear on-center neuron responds best to an intermediate spatial frequency whose bright bars fall over the on-center and whose dark bars fall over the opposing surround. When the spatial frequency is low, the signals from the center and surround oppose one another thus diminishing sensitivity. When the spatial frequency is high, the stimulus is averaged by the center again diminishing the response. From the response to harmonic stimuli, one can derive the spatial structure of the receptive field.
</figcaption>
</figure>
</div>
<p>To measure a neuron’s contrast sensitivity function, we determine the amount of contrast necessary in the stimulus that is required to elicit a criterion level of response from the neuron. When a contrast pattern is ineffective at influencing the neuron, we need to present the pattern at high contrast to elicit the response. When a pattern is well-suited to the neuron’s receptive field, a small amount of contrast will elicit the criterion response level. We call the amount of necessary to elicit the criterion response the <em>contrast threshold</em>. The inverse of contrast threshold is called <em>contrast sensitivity</em>.</p>
<p>From <a href="#fig-rf-freq" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-rf-freq</span></a>, you can see how a center-surround ganglion cell will respond to cosinusoidal patterns whose peak is centered over the receptive field of the neuron. When the spatial frequency is very low, a bright bar in the stimulus covers both the excitatory center and the inhibitory surround and the steady-state response is small. The most effective spatial frequency has bright bars imaged on the excitatory part of the linear receptive field, and dark bars on the opposing surround. This spatial frequency is well-matched to the receptive field and we will observe a strong neural response. If the frequency is higher still, parts of the cosinusoid greater and less than the mean both fall within the excitatory and inhibitory regions. The net effect of the stimulus averages out to a small response, so that high spatial frequencies are ineffective stimuli.</p>
<p>We summarize the neuron’s response to harmonic functions at a range of spatial frequencies using the <em>contrast sensitivity function</em>. Different aspects of the function provide us with information about the neuron’s spatial receptive field. The most effective spatial frequency provides information about the overall size of the receptive field. The extent of the fall off in sensitivity at low spatial frequencies provides information about the strength of the opposing surround. Finally, the fall-off in sensitivity at high spatial frequencies describes the size of the receptive field center since the highest spatial frequency the cell responds to is limited by the size of the receptive field center. Neurons with small receptive field centers respond well to high spatial frequency targets, while neurons with large centers do not.</p>
<div id="fig-parvo-csf" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-parvo-csf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/parvoCSF.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-parvo-csf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.19: Contrast sensitivity function of a neuron in the parvocellular layers of the monkey lateral geniculate nucleus. This neuron responds best to a spatial frequency near 5 cycles per degree. Notice that the opposing surround reduces the sensitivity to low spatial frequency patterns. Each grating pattern drifted across the retina at a velocity so that each point on the retina saw one 5.2 cycles of the pattern each second. The symbol on the vertical axis is the contrast sensitivity to a uniform spatial pattern flickering at 5.2 Hz. (Source: <span class="citation" data-cites="derrington1984-contrastsensitivity">Derrington and Lennie (<a href="#ref-derrington1984-contrastsensitivity" role="doc-biblioref">1984</a>)</span>).
</figcaption>
</figure>
</div>
<p><a href="#fig-parvo-csf" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-parvo-csf</span></a> shows a contrast sensitivity function from a linear cells in the parvocellular layers of a monkey lateral geniculate nucleus. The receptive fields of these neurons are indistinguishable from the receptive fields of midget ganglion cells<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<p>The contrast sensitivity function of a retinal ganglion cell is an alternative way to represent the cell’s receptive field. There are several characteristic features of retinal ganglion cell contrast sensitivity functions. First, retinal ganglion cell contrast sensitivity functions are single-peaked. Single-peaked contrast sensitivity functions are called <em>bandpass</em> and the peak-frequency is called the <em>center</em> frequency. With experience, the contrast sensitivity function becomes an intuitive way to understand some aspects of the neuron’s receptive field.</p>
</section>
<section id="why-contrast-patterns-are-important" class="level3" data-number="5.4.3">
<h3 data-number="5.4.3" class="anchored" data-anchor-id="why-contrast-patterns-are-important"><span class="header-section-number">5.4.3</span> Why contrast patterns are important</h3>
<p>In early studies of the neural response to light, the stimulus intensity, <span class="math inline">\(I\)</span>, was treated as the input variable. In this case, the linear systems methods fail severely. If we wish to apply linear methods to characterizing the responses of retinal ganglion cells, it is important to fix the mean level, and to treat the stimulus contrast, <span class="math inline">\(c\)</span>, as the input.</p>
<p>Formulating our experiments in terms of contrast does not make a nonlinear system linear. The nonlinear behavior of neurons becomes quite clear when we compare measurements at different mean levels. But, by organizing our measurements around the contrast responses at a fixed mean level, we can use linear methods to characterize the receptive field for perturbations around the mean level. To describe the neuron fully, we must combine the neuron’s response across many mean intensity levels. This forces us to acknowledge the nonlinear aspects of the neuron’s response.</p>
<p>The change in the system performance as we vary the mean stimulus level is called <em>visual adaptation</em>. We can measure the effects of visual adaptation in individual neurons, beginning in the retina, as well as in the behavior of animals and people. The way in which performance of neurons and people change as the mean illumination varies, that is visual adaptation, is one of the most important topics in vision. By formulating our stimulus in terms of a mean intensity level and a contrast pattern, we segregate out the effects of visual adaptation from the local contrast effects. Thus, formulating our experimental input this way is an important decision that has ramifications for how we study many important aspects of vision.</p>
<p>Most of modern vision science relies uses contrast as the key experimental parameter. The linearities that I will describe in this chapter and the following chapters are usually measured in the contrast domain, at a fixed mean level. As we change the mean level, the properties of the linear system we estimate change as well. This is a fundamental non-linearity in the system’s behavior. A complete theory must weave together how the locally linear responses, on a single mean background, vary with the mean. We will review this topic, called <em>adaptation</em>, at the end of this chapter and then again in later chapters.</p>
</section>
<section id="connections-to-different-cone-types" class="level3" data-number="5.4.4">
<h3 data-number="5.4.4" class="anchored" data-anchor-id="connections-to-different-cone-types"><span class="header-section-number">5.4.4</span> Connections to Different Cone Types</h3>
<p>In the primate fovea, the center response of the midget ganglion cells depends on the light captured by a single cone. Hence, the centers will inherit the wavelength sensitivity of the photopigment in that cone’s outer segment. Parvocellular Pathway neurons with receptive fields near the primate fovea often have a center response that is either an <span class="math inline">\(R\)</span> or <span class="math inline">\(G\)</span> cone. roughly equal to the optical blur imposed by diffraction (2.4 – 4.2 minutes of arc), which is consistent with the center response being due to a single cone.</p>
<p>There are two views concerning the connections of cones to the opponent-surround responses in ganglion cell receptive fields. <span class="citation" data-cites="lennie1980-parallel">Lennie (<a href="#ref-lennie1980-parallel" role="doc-biblioref">1980</a>)</span> suggested that the surround is driven by a random collection of cones, including both the <span class="math inline">\(R\)</span> and <span class="math inline">\(G\)</span> types. <span class="citation" data-cites="reid1992">Reid and Shapley (<a href="#ref-reid1992" role="doc-biblioref">1992</a>)</span> attempted to measure the surround and concluded that only a single class of cones contributes to the surround response. When the center response of a cell in the parvocellular pathway is from a <span class="math inline">\(R\)</span> cone, the surround response is due to <span class="math inline">\(G\)</span> cones. Conversely, when the center is from the <span class="math inline">\(G\)</span> the surround is from the <span class="math inline">\(R\)</span>. At the moment, the question of the segregation of cone signals in the surround of parvocellular pathway neurons is unresolved (see also, <span class="citation" data-cites="gouras-evers1989">P. Gouras and Evers (<a href="#ref-gouras-evers1989" role="doc-biblioref">1989</a>)</span>).</p>
<p>There is some agreement that the centers and surround of neurons in the magnocellular pathway receive a signal from both cone types. An on-center parasol cell receives an excitatory signal from the <span class="math inline">\(R\)</span> and <span class="math inline">\(G\)</span> cones, while the the surround signal is inhibitory and originates in both of these cone classes. The relative strength of the signals from these cone classes to the surround may vary (<span class="citation" data-cites="derrington1984-chromaticmechanisms">Derrington, Krauskopf, and Lennie (<a href="#ref-derrington1984-chromaticmechanisms" role="doc-biblioref">1984</a>)</span>).</p>
<p><span class="citation" data-cites="mariani1984">Mariani (<a href="#ref-mariani1984" role="doc-biblioref">1984</a>)</span> and <span class="citation" data-cites="dacey1994-blueon">Dennis M. Dacey and Lee (<a href="#ref-dacey1994-blueon" role="doc-biblioref">1994</a>)</span> have shown that the signals from the <span class="math inline">\(B\)</span> cones are coded within a specialized visual stream. Neurons that receive a signal from the <span class="math inline">\(B\)</span> cones have large receptive fields (18 min). As I noted in <a href="#sec-image-formation" class="quarto-xref"><span class="quarto-unresolved-ref">sec-image-formation</span></a>, the chromatic aberration of the optics is very strong in the short-wavelength region. Since the image from a short-wavelength light source will be blurred, the large size of these receptive fields is not necessarily a disadvantage. Mariani’s anatomical studies described the existence of bipolar neurons that make contact with a few widely spaced cones that appeared to be consistent with the <span class="math inline">\(B\)</span> cone mosaic. His observations suggest that the spatial connectivity of the <span class="math inline">\(B\)</span> cone signals also plays a role in creating large center receptive fields (see also, <span class="citation" data-cites="kouyama1992">Kouyama and Marschak (<a href="#ref-kouyama1992" role="doc-biblioref">1992</a>)</span>).</p>
<p>D. Dacey and B. Lee have confirmed the existence of a visual stream specialized for carrying information about the <span class="math inline">\(B\)</span> cone signal and made several important and novel observations. First, Dacey showed that there is a morphologically distinct type of retinal ganglion responsible for carrying the <span class="math inline">\(B\)</span> cone signal. These <em>bistratified</em> ganglion cells have dendritic trees that are stratified into two tiers near the inner and outer borders of the inner plexiform layer where the on- and off-center receptive field neurons stratify. Based on the anatomical connectivity of these neurons, Dacey suggested that these neurons carry a <span class="math inline">\(B\)</span> cone excitatory signal. Using electrophysiological measurements, Dacey and Lee made two additional and surprising observations. First, their sample of midget and parasol ganglion cells contained no input from the <span class="math inline">\(B\)</span> cones. Second, they showed that all of the bistratified ganglion cells had a <span class="math inline">\(B\)</span> excitatory input (<span class="citation" data-cites="dacey1993-smallfieldbistratified">D. M. Dacey (<a href="#ref-dacey1993-smallfieldbistratified" role="doc-biblioref">1993</a>)</span>; <span class="citation" data-cites="dacey1994-blueon">Dennis M. Dacey and Lee (<a href="#ref-dacey1994-blueon" role="doc-biblioref">1994</a>)</span>).</p>
<p>The bistratified neurons send their outputs to the parvocellular layers of the lateral geniculate nucleus (<span class="citation" data-cites="rodieck1993-pathways">Rodieck, Brening, and Watanabe (<a href="#ref-rodieck1993-pathways" role="doc-biblioref">1993</a>)</span>). Using electrophysiological methods, one can measure receptive fields in that nucleus whose excitatory centers are driven by signals from the <span class="math inline">\(B\)</span> cones. It is also possible that these neurons project to the intercalated zones of the lateral geniculate. Because the sampling resolution of the <span class="math inline">\(B\)</span> cone mosaic is poor, we do not expect these neurons to make up a large fraction of the total population. Nonetheless, they are important since at present they are the only cell class known to carry the <span class="math inline">\(B\)</span> cone signal (<span class="citation" data-cites="wiesel-hubel1966">Wiesel and Hubel (<a href="#ref-wiesel-hubel1966" role="doc-biblioref">1966</a>)</span>; <span class="citation" data-cites="gouras1968">P. Gouras (<a href="#ref-gouras1968" role="doc-biblioref">1968</a>)</span>; <span class="citation" data-cites="derrington1984-chromaticmechanisms">Derrington, Krauskopf, and Lennie (<a href="#ref-derrington1984-chromaticmechanisms" role="doc-biblioref">1984</a>)</span>).</p>
</section>
<section id="spatio-temporal-analysis-lines-and-spots" class="level3 page-columns page-full" data-number="5.4.5">
<h3 data-number="5.4.5" class="anchored" data-anchor-id="spatio-temporal-analysis-lines-and-spots"><span class="header-section-number">5.4.5</span> Spatio-Temporal Analysis: Lines and Spots</h3>
<p>Up to now, we have considered only the steady-state response, thus excluding time in order to simplify our analysis. Now we consider how to include the temporal response of the neuron in our measurement of the receptive field.</p>
<p><a href="#fig-ec-pinto" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-ec-pinto</span></a> illustrates an average temporal response of a cat retinal ganglion cell to a flashed target. To obtain the curves shown in the figure, the experimenters presented the test light and recorded the resulting neural activity. If we present the test flash repeatedly, we will find that the resulting pattern of spikes differs slightly each time. The differences will be small, however, so that we can sum together all of the responses obtained from, say, 50 repetitions of the test flash. We can compute the average number of action potentials at each moment in time following the flash, and plot this as a curve. This curve is called the <em>peri-stimulus time histogram, (PSTH)</em>.</p>
<p>The data in <a href="#fig-ec-pinto" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-ec-pinto</span></a> and other experimental measurements have shown that for certain cells in the cat retina, linearity holds rather well (<span class="citation" data-cites="enroth-cugell1984-diversity">C. Enroth-Cugell and Robson (<a href="#ref-enroth-cugell1984-diversity" role="doc-biblioref">1984</a>)</span>). Linearity has not been extensively tested in primate retina. To a fair approximation, linearity has been confirmed in measurements in the parvocellular pathway within the primate lateral geniculate nucleus (<span class="citation" data-cites="derrington1984-contrastsensitivity">Derrington and Lennie (<a href="#ref-derrington1984-contrastsensitivity" role="doc-biblioref">1984</a>)</span>). Hence, based on linear methods we can measure the responses to a collection of basic stimuli and use these responses to predict the responses to many other stimuli.</p>
<div id="fig-st-receptive-field" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-st-receptive-field-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/stReceptiveField.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-st-receptive-field-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.20: The space-time receptive field of a linear neuron can be estimated by measuring the temporal responses to briefly flashed lines. (a) A simulation of the temporal response to briefly flashed lines positioned either in the center or the surround portion of the receptive field. (b) A surface plot showing simulated temporal responses to individual lines at different positions within the receptive field. Such a collection of measurements can be used to predict a linear neuron’s response to any one-dimensional time-varying stimulus. Hence, these measurements are one way to define the space-time receptive field of the neuron.
</figcaption>
</figure>
</div>
<p>Panel (a) of <a href="#fig-st-receptive-field" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-st-receptive-field</span></a> shows two simulated PSTHs for an on-center cell response to a briefly flashed line. One PSTH shows the simulated response to a line flashed over the center of the receptive field, and the second PSTH is for a line flashed over the opposing surround. By measuring the responses to briefly flashed lines at many receptive field positions, we can specify the <em>space-time receptive field</em> of the neuron (<span class="citation" data-cites="stevens1976-orglgn">Stevens and Gerstein (<a href="#ref-stevens1976-orglgn" role="doc-biblioref">1976</a>)</span>). I have collected a series of these simulated responses in a surface plot shown in panel (b) of <a href="#fig-st-receptive-field" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-st-receptive-field</span></a>. One axis of the figure measures time and the second axis describes spatial position of the test line. Each curve along the time axis shows a simulated PSTH for a single spatial position of the line. When the position of the line is in the receptive field center, the simulated response is large and begins soon after the stimulus. When the line is positioned over the receptive field surround, the simulated response is weaker, delayed, and of opposite sign.</p>
<p>Since any one-dimensional time-varying stimulus is the sum of a set of briefly flashed lines, a collection of measurements like the simulations in panel (b) <a href="#fig-st-receptive-field" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-st-receptive-field</span></a> permit us to predict the response to any such stimulus. Such measurements define the space-time receptive field of this simulated neuron for one spatial dimension. This method of defining space-time receptive fields has been applied mainly to study the cat visual pathway (<span class="citation" data-cites="stevens1976-orglgn">Stevens and Gerstein (<a href="#ref-stevens1976-orglgn" role="doc-biblioref">1976</a>)</span>; <span class="citation" data-cites="palmer1981">Palmer and Davis (<a href="#ref-palmer1981" role="doc-biblioref">1981</a>)</span>; <span class="citation" data-cites="emerson1992">Emerson, Bergen, and Adelson (<a href="#ref-emerson1992" role="doc-biblioref">1992</a>)</span>).</p>
</section>
<section id="spatio-temporal-measurements-harmonic-functions" class="level3 page-columns page-full" data-number="5.4.6">
<h3 data-number="5.4.6" class="anchored" data-anchor-id="spatio-temporal-measurements-harmonic-functions"><span class="header-section-number">5.4.6</span> Spatio-Temporal Measurements: Harmonic Functions</h3>
<p>It is also possible to measure receptive field properties using harmonic functions, though in this case, we need to use harmonic functions in space and time. We can create space-time harmonic functions by multiplying cosinusoidal contrast patterns in space and time, creating a stimulus called a <em>contrast-reversing grating</em>. Such a pattern is the product of a spatial harmonic with frequency <span class="math inline">\(f_x\)</span> cycles per degree and a temporal harmonic with frequency <span class="math inline">\(f_t\)</span> Hz. The formula for a contrast-reversing grating made from cosinusoids is</p>
<p><span class="math display">\[
I(x) = \left[1.0 + \cos(2\pi f_t t)\cos(2\pi f_x x)\right]\mu.
\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the mean background intensity.</p>
<div id="fig-contrast-reversal" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-contrast-reversal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/contrastReversal.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-contrast-reversal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.21: Space-time representations of a contrast-reversing grating. At each moment in time this image is a cosinusoidal spatial pattern; the amplitude of the spatial pattern varies cosinusoidally over time. The contrast-reversing space-time pattern is represented as a two-dimensional surface plot in (a) and as an intensity image in (b).
</figcaption>
</figure>
</div>
<p><a href="#fig-contrast-reversal" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-contrast-reversal</span></a> shows the contrast-reversing in two different forms. At each moment in time the grating is a one-dimensional spatial frequency grating, with spatial frequency <span class="math inline">\(f_x\)</span>. At each point in space the time-varying contrast is a cosinusoidal function of time, with temporal frequency <span class="math inline">\(f_t\)</span>. In part (a) of the figure the function is shown as a surface plot. One axis of the plot represents time and the other space. Individual lines in both of these dimensions are sinusoidal. In part (b) of the figure the function is shown as an intensity image. Again, one dimension of the image represents time and the other space. The image intensity is bright at those points where the function has positive contrast and dark where the function has negative contrast.</p>
<p>Neurons in the lateral geniculate nucleus respond linearly for stimuli as high as 30 percent contrast. Hence, it is appropriate to use linear methods to measure the spatial-receptive fields of these neurons. Moreover, since the receptive field of neurons in the retinal and lateral geniculate nucleus in the parvocellular pathway are even-symmetric, we can measure the space-time contrast sensitivity function using only cosinusoidal functions centered on the receptive field. Because the neurons are linear and temporally shift-invariant, the PSTH is a harmonic function at the same temporal frequency of the input stimulus, <span class="math inline">\(f_t\)</span>. The amplitude and phase of the PSTH modulation depends on the temporal and spatial frequency of the contrast-reversing pattern used as an input.</p>
<div id="fig-dl" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-dl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/DL.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="501">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-dl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.22: The response to contrast-reversing harmonic patterns of a neuron in the parvocellular layers of the lateral geniculate nucleus. The two horizontal axes measure the spatial and temporal frequency of the contrast-reversing pattern. The height of the surface measures the response amplitude of the neuron’s PSTH. Notice that the loss of temporal frequency sensitivity depends on the spatial frequency: the temporal sensitivity falls off more rapidly at higher spatial frequencies. The surface plot was created by interpolating measurements reported by <span class="citation" data-cites="derrington1984-contrastsensitivity">Derrington and Lennie (<a href="#ref-derrington1984-contrastsensitivity" role="doc-biblioref">1984</a>)</span>.
</figcaption>
</figure>
</div>
<p>The response to contrast-reversing patterns of a parvocellular neuron in the monkey lateral geniculate nucleus is shown in <a href="#fig-dl" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-dl</span></a>. This surface plot was derived by interpolating measurements reported by <span class="citation" data-cites="derrington1984-contrastsensitivity">Derrington and Lennie (<a href="#ref-derrington1984-contrastsensitivity" role="doc-biblioref">1984</a>)</span>. This cell responded to temporal and spatial modulations up to 15 Hz and 15 cycles per degree. From the shape of the neuron we can make several observations about the neuron’s responsivity. First, the reduced sensitivity at low spatial frequencies shows that the neuron had a significant opponent surround. Second, the neuron responds well to all tested temporal frequencies when we measured with a low spatial frequency stimulus, but the neuron responds poorly at high temporal frequencies when measured using a high spatial frequency stimulus. Since the response to the high spatial frequency stimulus is mediated through the on-center, the data show that the temporal sensitivity from the on-center and opposing surround may be different. It is time to consider the general question of the interdependence of spatial and temporal sensitivity.</p>
</section>
<section id="sec-retina-separability" class="level3" data-number="5.4.7">
<h3 data-number="5.4.7" class="anchored" data-anchor-id="sec-retina-separability"><span class="header-section-number">5.4.7</span> Space-time separability</h3>
<p>We have defined the neuron’s receptive using two complementary representations. In one case, the we have defined the receptive field using briefly flashed lines, and in the second case we have defined the receptive field using harmonic functions of space-time. We can use either method to measure and describe a linear neuron’s receptive field.</p>
<p>No matter which description we use, the neuron’s sensitivity depends jointly on space and time. When our description of the receptive field includes both space and time, how can we define a neuron’s spatial receptive field? Or, how can we define its temporal receptive field?</p>
<p>Suppose that we refer to the neuron’s space-time receptive field, illustrated in <a href="#fig-st-receptive-field" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-st-receptive-field</span></a> (b), using the function <span class="math inline">\(\mathbf{R}(x,t)\)</span>. This function defines the response of the neuron to a line briefly flashed at position <span class="math inline">\(x\)</span> at time <span class="math inline">\(t\)</span> following the flash. We can ask whether a neuron has a unique <em>spatial</em> receptive field by examining this function at several different moments in time. That is, we might fix time at a value of <span class="math inline">\(t_1\)</span> and consider the function of position, <span class="math inline">\(\mathbf{R}(x,t_1)\)</span>, that defines the spatial receptive field at time <span class="math inline">\(t_1\)</span>. We can compare this spatial receptive field with the measurements at a second time, say, <span class="math inline">\(\mathbf{R}(x,t_2)\)</span>. We would say that the neuron has a unique spatial receptive field when the two functions are essentially the same, say,</p>
<p><span class="math display">\[
\mathbf{R} (x,t_1) = a \mathbf{R} (x,t_2)
\]</span></p>
<p>where <span class="math inline">\(a\)</span> is a scalar constant. If the spatial receptive field at each moment in time is the same except for a constant scale factor, then we say the neuron has a well-defined spatial receptive field.</p>
<p>A neuron will only have a well-defined spatial receptive field when the space-time receptive field is a <em>separable</em> function of space and time. Separability means that the receptive field function can be written as the product of two functions, one that depends only on space and the other that depends only on time, namely</p>
<p><span id="eq-retina-separability"><span class="math display">\[
\mathbf{R}(x,t) = S(x) T(t)
\tag{5.3}\]</span></span></p>
<p>If the space-time receptive field is separable, then, it follows from the definition that the spatial receptive fields at two times will always be related by the scale factor <span class="math inline">\(T(t_1)/T(t_2)\)</span>. In this case the function <span class="math inline">\(S(x)\)</span> is a meaningful definition of the neuron’s spatial receptive field. The function <span class="math inline">\(T(t)\)</span> is a meaningful definition of the neuron’s temporal impulse response function. If the space-time receptive field is separable, then it is possible to show that the space-time contrast sensitivity function will also be separable.</p>
<p>As the plots in panel (b) of <a href="#fig-st-receptive-field" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-st-receptive-field</span></a> and <a href="#fig-dl" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-dl</span></a> show, the space-time receptive fields of neurons in the parvocellular pathway are not space-time separable. Hence, these neurons do not have unique spatial or temporal response properties<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. In part because of this complexity, it is important to go beyond the descriptions of the neuron’s response we obtain from linear measurements, and to build a model to predict the neuron’s response to space-time patterns.</p>
</section>
<section id="the-difference-of-gaussian-model" class="level3 page-columns page-full" data-number="5.4.8">
<h3 data-number="5.4.8" class="anchored" data-anchor-id="the-difference-of-gaussian-model"><span class="header-section-number">5.4.8</span> The Difference of Gaussian Model</h3>
<p>In the mid 1960s, R. W. Rodieck and Enroth-Cugell and Robson introduced a linear receptive field model that has served as the basis for most subsequent models of linear retinal ganglion cells. The basic model is important in vision science broadly since the ideas in the model have been used in many different areas including work in the visual psychophysics of spatial perception and in computer vision vision work addressed to edge-detection and image segmentation. The receptive field model is now called the <em>Difference of Gaussian</em> model (<span class="citation" data-cites="rodieck1965-quant">Rodieck (<a href="#ref-rodieck1965-quant" role="doc-biblioref">1965</a>)</span>; <span class="citation" data-cites="enroth-cugell1966">C. Enroth-Cugell and Robson (<a href="#ref-enroth-cugell1966" role="doc-biblioref">1966</a>)</span>, <span class="citation" data-cites="enroth-cugell1983-linear">C. Enroth-Cugell et al. (<a href="#ref-enroth-cugell1983-linear" role="doc-biblioref">1983</a>)</span>).</p>
<div id="fig-dog" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-dog-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/dog.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-dog-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.23: A linear model of the space-time receptive field. The neural response depends on the linear sum of two independent mechanisms, a center and an opposing surround. (a) The spatial sensitivity of the center and surround mechanism both follow a Gaussian curve. The linespreads of the two mechanism are shown here. (b) The signals are summed separately within the center mechanism and the surround mechanism. The signal from the surround mechanism is temporally delayed and added to the signal from the center mechanism.
</figcaption>
</figure>
</div>
<p>The difference of Gaussian model supposes that the neural response results from the combined signal of two separate mechanisms called the <em>center</em> and the <em>surround</em>. The center mechanism receives all of its input from a small central region and the surround mechanism receives its input from a region that includes the center and the surrounding region.</p>
<p>Both the center and surround are assumed to respond to contrast stimuli as space-time separable linear systems. Because each mechanism is separable, we can describe them as having meaningful spatial and temporal sensitivities. The curves describing the spatial sensitivity of the center and surround mechanisms are shown in <a href="#fig-dog" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-dog</span></a> (a). Both curves follow the shape of a <em>Gaussian distribution</em>, also known as the <em>normal</em> curve.</p>
<p>According to the difference of Gaussian model, the output of the neuron can be predicted by summing together the temporal response from the center mechanism with a temporal signal from the surround mechanism. The model further assumes that the temporal response from the surround is different from the temporal response of the center, generally being slower to develop over time. Because of this delay between the center and surround responses, the behavior of the cell as a whole is not space-time separable even though the responses of the component mechanisms are space-time separable. Hence, the model neuron does not have a unique spatial receptive field, nor does it have a unique temporal response function.</p>
<p>The difference of Gaussian model has been useful to vision scientists in several different ways. First, the model simplifies our calculations and thinking about receptive fields. The difference of Gaussian model predicts the response of neurons from a calculation that requires us to specify only a few unknown parameters, such as the width of the center and surround mechanisms receptive fields. The model provides a very efficient method of describing neural space-time receptive fields, and thus a convenient way of comparing the receptive fields of neurons.</p>
<p>Just as important, the model provides a framework for posing new and interesting questions. You should notice that the idea of a center and surround mechanism are entirely theoretical. I have not offered any direct proof of their existence. By building a model to efficiently describe the results, we have generated a new hypothesis about how the responses of neurons are created. In probing to identify whether these are merely useful theoretical tools, or whether there are true anatomical center and surround pathways, we will be led to explore new and interesting aspects of the visual encoding of light in the retina.</p>
<p>Finally, the model is specified in enough detail that it can be used in a variety of branches of vision science. As we shall see in later chapters, the difference of Gaussian model has been used as a key element to describe some of the limitations in human visual sensitivity to patterns. The model has also been used to describe certain aspects of how computational models of how images are represented in the visual pathways.</p>
</section>
</section>
<section id="retinal-light-adaptation" class="level2 page-columns page-full" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="retinal-light-adaptation"><span class="header-section-number">5.5</span> Retinal Light Adaptation</h2>
<p>We have divided the study of receptive fields into two parts. We began by studying the neuron’s response to contrast patterns presented on a fixed mean background. Contrast patterns are perturbations about the mean background field; by studying the responses to these stimuli we have been able to apply linear methods successfully to specify the transformation from light signal to neural impulses.</p>
<p>When we measure with respect to contrast instead of absolute intensity tests of linearity have a better chance of succeeding. To a significant degree, this is because contrast stimuli limit the range of intensities in the the image. For example, the peak intensity in a 100 percent contrast sinusoidal pattern is only a factor of 2 greater than the mean background intensity. The range of contrasts that we encode in a typical image, from the least contrast we can detect to 100 percent contrast, is no more than 2 orders of magnitude.</p>
<p>Through the course of a day, however, the range of image absolute intensities we experience typically exceeds 6 orders of magnitude. The visual pathways do not remain linear over this enormous range. When we study the response to contrast stimuli, we are attending to the local response of a globally nonlinear system. To fully understand the properties of neurons, we must also analyze how their responses change as we vary the mean background level. The changing neural and behavioral responses as a function of mean background intensity varies is called <em>visual adaptation</em>. In this section we will consider how to the locally linear measures we have developed using contrast must be extended when we consider the visual pathways over a wider range of mean signal levels.</p>
<section id="contrast-sensitivity-dependence-on-mean-intensity" class="level3 page-columns page-full" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="contrast-sensitivity-dependence-on-mean-intensity"><span class="header-section-number">5.5.1</span> Contrast Sensitivity: Dependence on Mean Intensity</h3>
<p><a href="#fig-csf-vs-background" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-csf-vs-background</span></a> (a) shows several contrast sensitivity functions from a cat retinal ganglion cell. These functions were measured on a wide range of mean intensities. When the mean intensity is relatively low, the neuron responds poorly to relatively high spatial frequencies<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. At low background intensities the contrast sensitivity function shows little bandpass behavior, suggesting that there is little effect of the inhibitory surround. As the background intensity increases, the contrast sensitivity function changes shape. The reduced sensitivity to low frequency sensitivity stimuli becomes apparent, indicating that the opponent surround is more significant.</p>
<p>The change in the contrast sensitivity function with mean background intensity is a clue about how visual adaptation compensates for the change in mean background intensity. At low mean levels the neuron simply sums all of the quanta incident within the receptive field. At these low levels there is little surround inhibition, and thus there is little fall-off in the low frequency portion of the contrast sensitivity function. At higher mean levels, when quanta are more abundant, and the spatial receptive field of the neuron becomes relatively more sensitive to stimuli whose intensity varies within the receptive field. The opposing surround means that the neuron no longer sums the response to every quantum. Instead, the neuron responds better when there is variation in the intensity level within the spatial receptive field.</p>
<p>At the high mean background intensities, the contrast sensitivity functions are rather similar. For example, the three highest mean intensities used in the measurements in <a href="#fig-csf-vs-background" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-csf-vs-background</span></a> differ by a factor of 100. Yet, in the low spatial frequency range the contrast sensitivity curves measured at these levels differ only by about a factor of three. Panel (b) in the figure shows the relatively small change in contrast sensitivity with mean background by comparing the cell’s contrast sensitivity to a 0.2 cpd pattern measured on different background intensities. As mean intensity changes over five orders of magnitude, the contrast sensitivity to this pattern varies one order of magnitude.</p>
<div id="fig-csf-vs-background" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-csf-vs-background-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/csf.vs_.background.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-csf-vs-background-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.24: Contrast sensitivity function of a cat retinal ganglion cell measured at different mean intensity levels. (a) The curves correspond to contrast sensitivity measurements made on backgrounds at 16, 5.1, 0.016, and 0.0005 candelas per meter squared. The shape of the contrast sensitivity function becomes increasingly lowpass, and less bandpass, as the background illumination decreases. (b) The contrast sensitivity to a 0.2 cpd spatial pattern varies by less than a factor of ten as the mean level varies over near five orders of magnitude. (Source: <span class="citation" data-cites="enroth-cugell1966">C. Enroth-Cugell and Robson (<a href="#ref-enroth-cugell1966" role="doc-biblioref">1966</a>)</span>).
</figcaption>
</figure>
</div>
<p>The relative constancy in contrast sensitivity reinforces the view that the response of the neuron is more closely coupled to the stimulus contrast than the absolute intensity level. This suggests that the contrast variable may be the key stimulus variable represented by the neuron’s activity.</p>
<p>Image contrast and image intensity are inter-related quantities. The relatively constant sensitivity to contrast implies that the neuron’s sensitivity to absolute light level varies with changes in mean intensity level; <a href="#fig-rgc-weber" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-rgc-weber</span></a> shows this variation in sensitivity to light. The vertical axis of the graph measures the logarithm of the light intensity of an incremental flash needed to cause a fixed increase in firing rate from the spontaneous rate. This is a measurement of the threshold sensitivity to the incremental test flash. The horizontal axis of the graph measures logarithm of the mean background intensity. Since the slope of the increasing portion of the graph is close to one, we can conclude that the threshold increases roughly in proportion to mean background intensity. This relationship between threshold and background level was first discovered from measurements of human behavior. The relationship is called <em>Weber’s law</em>, to honor the scientist who first discovered the principle.</p>
<p>As the mean intensity of the background varies, we can find other aspects to the change in the neural response as well. Plotted as insets to the figure are the PSTHs of the measurements to these incremental threshold flashes. The timecourse of the response to the incremental flash varies with mean intensity level, becoming somewhat brisker with sharper signals at the onset and offset of the test flash. Thus, we see that the temporal response of the neuron, like the spatial contrast sensitivity, varies with mean intensity level. These adaptations probably occur to take advantage of the improved quality of the signal available at higher light levels.</p>
</section>
<section id="comparison-with-behavioral-contrast-sensitivity" class="level3 page-columns page-full" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="comparison-with-behavioral-contrast-sensitivity"><span class="header-section-number">5.5.2</span> Comparison with Behavioral Contrast Sensitivity</h3>
<div id="fig-rgc-weber" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-rgc-weber-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/rgc.weber_.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-rgc-weber-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.25: Threshold sensitivity as a function of background intensity measured on a cat retinal ganglion cell. The threshold intensity of an incremental test flash required to elicit a criterion peak firing rate in a retinal ganglion cell was measured. The test flash was presented on a large steady background, The logarithm of the threshold intensity of the test flash grows linearly with the logarithm of the mean background intensity, and the slope is close to one. Hence, the threshold is intensity is proportional to the background intensity. The insets within the figure show the PSTH and demonstrate that the timecourse of the ganglion cell changes with intensity level. On higher backgrounds, transient overshoots and undershoots are evident. (Source: <span class="citation" data-cites="enroth-cugell1977-conesig">C. Enroth-Cugell, Hertz, and Lennie (<a href="#ref-enroth-cugell1977-conesig" role="doc-biblioref">1977</a>)</span>).
</figcaption>
</figure>
</div>
<p>Sensitivity to contrast and sensitivity to absolute light level are complementary measures. When the threshold to the absolute light level is proportional to the background, as Weber’s law predicts, sensitivity to contrast will be precisely constant. In most cases, however, Weber’s Law is only a rough approximation. For example, consider the contrast sensitivity functions plotted in <a href="#fig-csf-vs-background" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-csf-vs-background</span></a>. Were Weber’s law exact, all of the contrast sensitivity functions would overlap. Plainly, this is not so. Moreover, the quality of the Weber’s law approximation depends on the spatial pattern of the stimulus. The approximation is better for low spatial frequency patterns than for high spatial frequency patterns.</p>
<p>Reasoning based on these types of approximations is part of the challenge confronting the student of biological systems. The laws we discover don’t have the same precision as physical laws. It is often a question of judgment as to whether the approximation to a law we see in a biological measurement is adequate to support a principled view about the function of a neuron or a visual pathway. In this case, there is some consensus that contrast is a key variable reported out by the retinal ganglion cells. In part, the consensus has developed from the neural response data we have reviewed in this chapter. And, in part, the consensus depends on the analysis that we will undertake later in this volume, in which we consider the important signals for visual function. <!-- \\nocite{ShapleyReviewArticle,WeberCitation}--></p>
<p>There is a third type of evidence that we should consider as well: this is the question of whether the properties of the contrast sensitivity function we measure at the level of individual neurons can be detected in the properties of the animal’s behavior. In <a href="#sec-image-formation" class="quarto-xref"><span class="quarto-unresolved-ref">sec-image-formation</span></a> and <a href="#sec-photoreceptor-mosaic" class="quarto-xref"><span class="quarto-unresolved-ref">sec-photoreceptor-mosaic</span></a>, and <a href="#sec-wavelength-encoding" class="quarto-xref"><span class="quarto-unresolved-ref">sec-wavelength-encoding</span></a> we have seen several succesful comparisons between human behavior and physiological measurements.</p>
<p>The retinal ganglion cell contrast sensitivity functions have a counterpart in the behavioral contrast sensitivity functions. <span class="citation" data-cites="pasternak1981-luminance">Pasternak and Merigan (<a href="#ref-pasternak1981-luminance" role="doc-biblioref">1981</a>)</span> measured behavioral contrast sensitivity functions in the cat on a variety of mean background intensities (see <a href="#fig-behavior-csf" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-behavior-csf</span></a>). The behavioral contrast sensitivity functions parallel the neural contrast sensitivity functions. For example, as the mean background intensity increases the behaviorally measured contrast sensitivity functions become more bandpass. Also, as the mean background intensity varies over six orders of magnitude, the contrast sensitivity changes by only one order of magnitude. Hence, there is good qualitative agreement between the response sensitivities of individual retinal ganglion cells and the animal as a whole.</p>
<div id="fig-behavior-csf" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-behavior-csf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/behaviorCsf.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-behavior-csf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.26: Behavioral contrast sensitivity functions of the cat measured on a variety of mean background intensities. Individual behavioral contrast sensitivity functions show the same qualitative properties as the contrast sensitivity functions of individual retinal ganglion cells. As the mean background intensity increases the contrast sensitivity function becomes increasingly bandpass (panel a). As the mean background intensity varies over six orders of magnitude, the contrast sensitivity of a 0.3 cpd target changes by only one order of magnitude (panel b). (Source: <span class="citation" data-cites="pasternak1981-luminance">Pasternak and Merigan (<a href="#ref-pasternak1981-luminance" role="doc-biblioref">1981</a>)</span>).
</figcaption>
</figure>
</div>
<p>The agreement between neural measurements and behavioral measurements demonstrates that the information present in the responses of individual neurons is similar to the information available to the cat making its behavioral judgments concerning the presence of the contrast pattern. This does not mean, however, that the responses of individual retinal ganglion cells govern the animal’s behavior. We have already seen, for example, that the information encoded about wavelength by the cone photoreceptors is equivalent to the information available to the human when making a color-match. Yet, it is certain that when we formulate our conscious decisions about a color-match we do not have access to the information at the cones themselves. The agreement between neural and behavioral responses is an abstract one, an agreement at a theoretical level. We shall see this type of comparison again as we move on to study visual cortex and human behavior. As we do, remember that a good method of comparing neural and behavioral responses is to analyze the information available at a point in the visual pathway with the information available to the human making a behavioral decision.</p>



<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-andrews1997-lgn" class="csl-entry" role="listitem">
Andrews, T J, S D Halpern, and D Purves. 1997. <span>“Correlated Size Variations in Human Visual Cortex, Lateral Geniculate Nucleus, and Optic Tract.”</span> <em>J. Neurosci.</em> 17 (8): 2859–68. <a href="http://dx.doi.org/10.1523/jneurosci.17-08-02859.1997">http://dx.doi.org/10.1523/jneurosci.17-08-02859.1997</a>.
</div>
<div id="ref-barlow1957-dark" class="csl-entry" role="listitem">
Barlow, H. B., R. Fitzhugh, and S. W. Kuffler. 1957. <span>“Change of Organization in the Reveptive Fields of the Cat’s Retina During Dark Adaptation.”</span> <em>J. Neurophysiology</em> 137: 338–45.
</div>
<div id="ref-boycott-wassle1974-rgctypescat" class="csl-entry" role="listitem">
Boycott, B. B., and H. Wässle. 1974. <span>“The Morphological Types of Ganglion Cells of the Domestic Cat’s Retina.”</span> <em>J. Physiol.</em> 240: 397–419.
</div>
<div id="ref-dacey1992-mpganglion" class="csl-entry" role="listitem">
Dacey, D M, and M R Petersen. 1992. <span>“Dendritic Field Size and Morphology of Midget and Parasol Ganglion Cells of the Human Retina.”</span> <em>Proceedings of the National Academy of Sciences of the United States of America</em> 89 (20): 9666–70.
</div>
<div id="ref-dacey1993-smallfieldbistratified" class="csl-entry" role="listitem">
Dacey, D. M. 1993. <span>“Morphology of a Small-Field Bistratified Ganglion Cell Type in the Macaque and Human Retina.”</span> <em>Visual Neurosci.</em> 10: 1081–98.
</div>
<div id="ref-dacey1994-blueon" class="csl-entry" role="listitem">
Dacey, Dennis M, and Barry B Lee. 1994. <span>“The ’Blue-on’ Opponent Pathway in Primate Retina Originates from a Distinct Bistratified Ganglion Cell Type.”</span> <em>Nature</em> 367 (6465): 731–35.
</div>
<div id="ref-derrington1984-chromaticmechanisms" class="csl-entry" role="listitem">
Derrington, A. M., J. Krauskopf, and P. Lennie. 1984. <span>“Chromatic Mechanisms in Lateral Geniculate Nucleus of Macaque.”</span> <em>J. Physiol.</em> 357: 241–65.
</div>
<div id="ref-derrington1984-contrastsensitivity" class="csl-entry" role="listitem">
Derrington, A. M., and P. Lennie. 1984. <span>“Spatial and Temporal Contrast Sensitivities of Neurons in the Lateral Geniculate Nucleus of Macaque.”</span> <em>J. Physiol.</em> 357: 219–40.
</div>
<div id="ref-emerson1992" class="csl-entry" role="listitem">
Emerson, R. C., J. R. Bergen, and E. H. Adelson. 1992. <span>“Directionally Selective Complex Cells and the Computation of Motion Energy in Cat Visual Cortex.”</span> <em>Vision Research</em> 32 (August): 203–18.
</div>
<div id="ref-enroth-cugell1977-conesig" class="csl-entry" role="listitem">
Enroth-Cugell, C., G. Hertz, and P. Lennie. 1977. <span>“Cone Signals in the Cat’s Retina.”</span> <em>J. Neurophysiol.</em> 269: 273–96.
</div>
<div id="ref-enroth-cugell1970-summation" class="csl-entry" role="listitem">
Enroth-Cugell, C., and L. H. Pinto. 1970. <span>“Algebraic Summation of Centre and Surround Inputs to Retinal Ganglion Cells of the Cat.”</span> <em>Nature</em> 226 (May): 458–59.
</div>
<div id="ref-enroth-cugell1966" class="csl-entry" role="listitem">
Enroth-Cugell, C, and J G Robson. 1966. <span>“The Contrast Sensitivity of Retinal Ganglion Cells of the Cat”</span> 187 (3): 517–52.
</div>
<div id="ref-enroth-cugell1984-diversity" class="csl-entry" role="listitem">
———. 1984. <span>“<a href="https://www.ncbi.nlm.nih.gov/pubmed/6698746">Functional Characteristics and Diversity of Cat Retinal Ganglion Cells. <span>Basic</span> Characteristics and Quantitative Description</a>.”</span> <em>Investigative Ophthalmology and Visual Science</em> 25 (3): 250–67.
</div>
<div id="ref-enroth-cugell1983-linear" class="csl-entry" role="listitem">
Enroth-Cugell, C, J G Robson, D E Schweitzer-Tong, and A B Watson. 1983. <span>“Spatio-Temporal Interactions in Cat Retinal Ganglion Cells Showing Linear Spatial Summation”</span> 341 (August): 279–307.
</div>
<div id="ref-gouras1968" class="csl-entry" role="listitem">
Gouras, P. 1968. <span>“Identification of Cone Mechanisms in Monkey Ganglion Cells.”</span> <em>J. Physiol.</em> 199: 533–47.
</div>
<div id="ref-gouras-evers1989" class="csl-entry" role="listitem">
Gouras, P, and H U Evers. 1989. <span>“Neural Systems Detecting Spectral Contrast Independently of Effective Energy Contrast: Where and How Does Color Vision Begin.”</span> In, edited by J. J. Kulikowski. Oxford: Pergamon Press.
</div>
<div id="ref-hartline1938-illumination" class="csl-entry" role="listitem">
Hartline, H K. 1938. <span>“<span>THE RESPONSE OF SINGLE OPTIC NERVE FIBERS OF THE VERTEBRATE EYE TO ILLUMINATION OF THE RETINA</span>.”</span> <em>American Journal of Physiology-Legacy Content</em> 121 (2): 400–415.
</div>
<div id="ref-kaplan-shapley1982-xycells" class="csl-entry" role="listitem">
Kaplan, Ehud, and Robert M Shapley. 1982. <span>“X and y Cells in the Lateral Geniculate Nucleus of Macaque Monkeys.”</span> <em>Journal of Physiology</em> 330: 125–43.
</div>
<div id="ref-kaplan-shapley1986-typesrgc" class="csl-entry" role="listitem">
———. 1986. <span>“The Primate Retina Contains Two Types of Ganglion Cells, with High and Low Contrast Sensitivity.”</span> <em>Proc. Natl. Acad. Sci. U.S.A.</em> 83: 2755–57.
</div>
<div id="ref-kouyama1992" class="csl-entry" role="listitem">
Kouyama, N., and D. W. Marschak. 1992. <span>“Bipolar Cells Speciffic for Blue Cones in the Macaque Retina.”</span> <em>J. Neurosci.</em> 12: 1233–52.
</div>
<div id="ref-kuffler1953-discharge" class="csl-entry" role="listitem">
Kuffler, S. W. 1953. <span>“Discharge Patters and Functional Organization of Mammalian Retina.”</span> <em>J. Neurophysiology</em> 16: 37–68.
</div>
<div id="ref-lennie1980-parallel" class="csl-entry" role="listitem">
Lennie, Peter. 1980. <span>“Parallel Visual Pathways: A Review.”</span> <em>Vision Research</em> 20: 561–94.
</div>
<div id="ref-levinthal1981" class="csl-entry" role="listitem">
Levinthal, A. G., R. W. Rodieck, and B. Dreher. 1981. <span>“Retinal Ganglion Cell Classe in the Old World Monkey.”</span> <em>Science</em> 213: 1139–42.
</div>
<div id="ref-lynch1992" class="csl-entry" role="listitem">
Lynch, J. J., L. C. L. Silveira, V. H. Perry, and W. H. Merigan. 1992. <span>“Visual Effects of Damage to p Ganglion Cells in Macaques.”</span> <em>Vis. Neurosci.</em> 8: 575–83.
</div>
<div id="ref-mariani1984" class="csl-entry" role="listitem">
Mariani, A. P. 1984. <span>“Bipolar Cells in the Monkey Retina Selective for the Cones Likely to Be Blue-Sensitive.”</span> <em>Nature</em> 308: 184–86.
</div>
<div id="ref-merigan1993-parallelprimatevisual" class="csl-entry" role="listitem">
Merigan, W H, and J H Maunsell. 1993. <span>“How Parallel Are the Primate Visual Pathways?”</span> <em>Annual Review of Neuroscience, Vol 34</em> 16: 369–402.
</div>
<div id="ref-merigan1991a-primatemotion" class="csl-entry" role="listitem">
Merigan, W. H., C. E. Byrne, and J. H. Maunsell. 1991. <span>“Does Primate Motion Perception Depend on the Magnocellular Pathway?”</span> <em>Journal of Neuroscience</em> 11 (11): 3422–29. <a href="https://doi.org/10.1523/JNEUROSCI.13-07-03180.1993">https://doi.org/10.1523/JNEUROSCI.13-07-03180.1993</a>.
</div>
<div id="ref-merigan1991b-plgnlesion" class="csl-entry" role="listitem">
Merigan, W. H., L. M. Katz, and J. H. Maunsell. 1991. <span>“The Effects of Parvocellular Lateral Geniculate Leasions on the Acuity and Contrast Sensitivity of Macaque Monkeys.”</span> <em>Journal of Neuroscience</em> 11: 994–1001.
</div>
<div id="ref-mountcastle1957-modality" class="csl-entry" role="listitem">
Mountcastle, V B. 1957. <span>“Modality and Opographic Properties of Single Neurons of Cat’s Somatic Sensory Cortex.”</span> <em>Neurophysiology</em> 20: 408–34.
</div>
<div id="ref-palmer1981" class="csl-entry" role="listitem">
Palmer, Chris R, and T. L. Davis. 1981. <span>“Receptive-Field Structure in Cat Striate Cortex.”</span> <em>Journal of Neurophysiology</em> 46: 260–76.
</div>
<div id="ref-pasternak1981-luminance" class="csl-entry" role="listitem">
Pasternak, Tatiana, and William H. Merigan. 1981. <span>“The Luminance Dependence of Spatial Vision in the Cat.”</span> <em>Vision Research</em> 21: 1333–40.
</div>
<div id="ref-perry1980-fovea" class="csl-entry" role="listitem">
Perry, V H, and A Cowey. 1980. <span>“The Projection of the Fovea to the Superior Colliculus in Rhesus Monkeys.”</span> <em>Vision Research</em> 5: 53–61.
</div>
<div id="ref-perry1981-xyganglion" class="csl-entry" role="listitem">
———. 1981. <span>“The Morphological Correlates of x- and y-Like Retinal Ganglion Cells in the Retina of Monkeys.”</span> <em>Exp. Brain Res.</em> 43: 226–28.
</div>
<div id="ref-perry1984-rgcsupcolliculus" class="csl-entry" role="listitem">
———. 1984. <span>“Retinal Ganglion Cells That Project to the Superior Colliculus and Pretectum in the Macaque Monkey.”</span> <em>Neuroscience</em> 12 (4): 1125–37.
</div>
<div id="ref-perry1984-dorsallgn" class="csl-entry" role="listitem">
Perry, V H, R. Oehler, and A Cowey. 1984. <span>“Retinal Ganglion Cells That Project to the Dorsal Lateral Geniculate Nucleus in the Macaque Monkey.”</span> <em>Neuroscience</em> 12 (4): 1101–23.
</div>
<div id="ref-polyak1941-retinabook" class="csl-entry" role="listitem">
Polyak, S L. 1941. <em>The Retina: <span>The</span> Anatomy and the Histology of the Retina in Man, Ape and Monkey, Including the Consideration of Visual Functions, the History of Physiological Optics, and the Histological Laboratory Technique</em>. Chicago, IL: University of Chicago Press.
</div>
<div id="ref-polyak1957-vertebratebook" class="csl-entry" role="listitem">
Polyak, S. L. 1957. <em>The Vertebrate Visual System</em>. Chicago, IL: University of Chicago Press.
</div>
<div id="ref-popova-cajal2017" class="csl-entry" role="listitem">
Popova, Maria. 2017. <span>“Beautiful Brain: The Stunning Drawings of Neuroscience Founding Father Santiago Ramón y Cajal,”</span> February.
</div>
<div id="ref-reichenbach-cajaldrawings2022" class="csl-entry" role="listitem">
Reichenbach, Andreas, and Andreas Bringmann. 2022. <span>“Retina: Neuroanatomy and Physiology,”</span> October, 955–1027. https://doi.org/<a href="https://doi.org/10.1007/978-3-030-88832-9_22">https://doi.org/10.1007/978-3-030-88832-9_22</a>.
</div>
<div id="ref-reid1992" class="csl-entry" role="listitem">
Reid, R. C., and R. M. Shapley. 1992. <span>“Spatial Structure of Cone Inputs to Receptive Fields in Primate Lateral Geniculate Nucleus.”</span> <em>Nature</em> 356: 716–18.
</div>
<div id="ref-rodieck1965-quant" class="csl-entry" role="listitem">
Rodieck, R. W. 1965. <span>“Quantitative Analysis of Cat Retinal Ganglion Cell Responses to Visual Stimuli.”</span> <em>Vision Research</em> 5: 583–601.
</div>
<div id="ref-rodieck1985-pmganglion" class="csl-entry" role="listitem">
Rodieck, R. W., K. F. Binmoeller, and J. D. Dineen. 1985. <span>“Parasol and Midget Ganglion Cells of the Human Retina.”</span> <em>J. Comp. Neurol.</em> 233: 115–32.
</div>
<div id="ref-rodieck1993-pathways" class="csl-entry" role="listitem">
Rodieck, R. W., R. K. Brening, and M. Watanabe. 1993. <em>The Origin of Parallel Visual Pathways</em>. Edited by Robert Shapley, R. M. Shapley, and Dominic Man-Kit Lam. Vol. 5. Cambridge, MA: MIT Press.
</div>
<div id="ref-schiller1978-lgn" class="csl-entry" role="listitem">
Schiller, P H, and J G Malpeli. 1978. <span>“Functional Specificity of Lateral Geniculate Nucleus Laminae of the Rhesus Monkey.”</span> <em>Journal of Neurophysiology</em> 41 (3): 788–97.
</div>
<div id="ref-schiller1990-channels" class="csl-entry" role="listitem">
Schiller, P. H., and N. K. Logothetis. 1990. <span>“The Color-Opponent and Broad-Based Channels of the Primate Visual System.”</span> <em>Trends Neurosci.</em> 10: 392–98.
</div>
<div id="ref-shapley1986-parallel" class="csl-entry" role="listitem">
Shapley, R. M. 1990. <span>“Visual Sensitivity and Parallel Retinocortical Channels.”</span> <em>Annu. Rev. Psy.</em> 41: 635–58.
</div>
<div id="ref-sherman-koch1990" class="csl-entry" role="listitem">
Sherman, S. Murray, and Christof Koch. 1990. <span>“Thalamus.”</span> In <em>The Synaptic Organization of the Brain</em>, edited by Gordon M. Shepherd. New York: Oxford University Press.
</div>
<div id="ref-sterling1994" class="csl-entry" role="listitem">
Sterling, P, D J Calkins, K J Klug, S J Schein, and Y Tsukamoto. 1994. <span>“Parallel Pathways from Primate Fovea.”</span> In <em>INVESTIGATIVE OPHTHALMOLOGY &amp; VISUAL SCIENCE</em>, 35:2001–1.
</div>
<div id="ref-stevens1976-orglgn" class="csl-entry" role="listitem">
Stevens, J. K., and G. L. Gerstein. 1976. <span>“Spatiotemporal Organization of Cat Lateral Genicular Receptive Fields.”</span> <em>J. Neurophysiol.</em> 39: 213–38.
</div>
<div id="ref-boycott-wassle-1991" class="csl-entry" role="listitem">
Wässle, H., and B. B. Boycott. 1991. <span>“Functional Architecture of the Mammalian Retina.”</span> <em>Physiological Reviews</em> 71 (2): 447–80. <a href="https://doi.org/10.1152/physrev.1991.71.2.447">https://doi.org/10.1152/physrev.1991.71.2.447</a>.
</div>
<div id="ref-watanabe-rodieck1989" class="csl-entry" role="listitem">
Watanabe, M., and R. Rodieck. 1989. <span>“Parasol and Midget Ganglion Cells of the Primate Retina.”</span> <em>J. Comp. Neurol.</em> 289: 434–54.
</div>
<div id="ref-wiesel-hubel1966" class="csl-entry" role="listitem">
Wiesel, T N, and D H Hubel. 1966. <span>“Spatial and Chromatic Interactions in the Lateral Geniculate Body of the Rhesus Monkey.”</span> <em>J. Neurophysiol.</em> 29 (6): 1115–56.
</div>
<div id="ref-yamashita1991-rodbipolar" class="csl-entry" role="listitem">
Yamashita, M, and H Wässle. 1991. <span>“Responses of Rod Bipolar Cells Isolated from the Rat Retina to the Glutamate Agonist 2-Amino-4-Phosphonobutyric Acid (<span>APB</span>).”</span> <em>J. Neurosci.</em> 11 (8): 2372–82. <a href="http://dx.doi.org/10.1523/jneurosci.11-08-02372.1991">http://dx.doi.org/10.1523/jneurosci.11-08-02372.1991</a>.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Some neurons have no axon, exerting their influence only at local interconnections at synapses within the dendritic field. The shape of a neuron’s dendritic field and its axonal branches are generally important features for distinguishing broad classes of neurons. We will use many features, including the locations of cell bodies, dendrites and axons; the size and shape of their cell bodies and dendritic fields; and, their interconnections with other neurons, to classify and understand retinal neurons.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In some books the dynamic range problem is treated by explaining that the photoreceptors respond to light intensity using a compressive function of intensity, such as a logarithmic or power function. A compressive function maps a light stimulus ranging over six orders of magnitude into neural responses of one to two orders of magnitude above their intrinsic variability. In the modern literature, this view has been substantially replaced by a formulation based on stimulus and response contrast.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>To describe a general linear receptive field, we must measure the neuron’s response using both sinusoidal and cosinusoidal contrast patterns. The receptive fields of retinal ganglion cells can be measured using only cosinusoids centered on the peak because the receptive fields are <em>even-symmetric</em>. A function is said to have even symmetry if <span class="math inline">\(f(x) = f(-x)\)</span>. A function has <em>odd symmetry</em> if <span class="math inline">\(f(x) = -f(-x)\)</span>. When a receptive field is even-symmetric, it will have zero response to any odd-symmetric inputs, so we need to measure only the response to even-symmetric inputs. For retinal ganglion cells, then, the contrast sensitivity function is a complete description of the receptive field in this case.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Although I will not go into the details here, by considering the connections to specific cone types you can convince yourself that the receptive fields will not be separable with respect to space and wavelength.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>In general, cats have very poor spatial resolution compared to primates. The spatial frequency range of this neuron, and cats’ performance as measured behaviorally, is far below the normal range for primate visual acuity.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./part-2-image-representation.html" class="pagination-link" aria-label="Introduction to Image Representation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Introduction to Image Representation</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter-6-the-cortical-representation.html" class="pagination-link" aria-label="Cortical Representation">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Cortical Representation</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>